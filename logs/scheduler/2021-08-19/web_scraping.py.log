[2021-08-19 00:42:22,875] {scheduler_job.py:181} INFO - Started process (PID=5548) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 00:42:22,889] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 00:42:22,890] {logging_mixin.py:104} INFO - [2021-08-19 00:42:22,889] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 00:42:23,039] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 00:42:24,373] {logging_mixin.py:104} INFO - [2021-08-19 00:42:24,372] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 00:42:24,455] {logging_mixin.py:104} INFO - [2021-08-19 00:42:24,455] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18 00:00:00+00:00
[2021-08-19 00:42:24,528] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 1.703 seconds
[2021-08-19 02:27:04,108] {scheduler_job.py:181} INFO - Started process (PID=5608) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:27:04,111] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:27:04,158] {logging_mixin.py:104} INFO - [2021-08-19 02:27:04,158] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:27:04,421] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:27:04,932] {logging_mixin.py:104} INFO - [2021-08-19 02:27:04,920] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:27:05,127] {logging_mixin.py:104} INFO - [2021-08-19 02:27:05,127] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18 00:00:00+00:00
[2021-08-19 02:27:05,329] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 1.269 seconds
[2021-08-19 02:27:40,660] {scheduler_job.py:181} INFO - Started process (PID=5660) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:27:40,737] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:27:40,739] {logging_mixin.py:104} INFO - [2021-08-19 02:27:40,739] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:27:41,124] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:27:41,652] {logging_mixin.py:104} INFO - [2021-08-19 02:27:41,651] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:27:41,893] {logging_mixin.py:104} INFO - [2021-08-19 02:27:41,893] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T03:15:00+00:00
[2021-08-19 02:27:42,194] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 1.742 seconds
[2021-08-19 02:28:13,172] {scheduler_job.py:181} INFO - Started process (PID=5702) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:28:13,180] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:28:13,182] {logging_mixin.py:104} INFO - [2021-08-19 02:28:13,181] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:28:13,236] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:28:13,365] {logging_mixin.py:104} INFO - [2021-08-19 02:28:13,365] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:28:13,438] {logging_mixin.py:104} INFO - [2021-08-19 02:28:13,438] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T04:00:00+00:00
[2021-08-19 02:28:13,488] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.328 seconds
[2021-08-19 02:28:43,562] {scheduler_job.py:181} INFO - Started process (PID=5756) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:28:43,574] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:28:43,580] {logging_mixin.py:104} INFO - [2021-08-19 02:28:43,580] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:28:43,630] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:28:43,723] {logging_mixin.py:104} INFO - [2021-08-19 02:28:43,723] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:28:43,791] {logging_mixin.py:104} INFO - [2021-08-19 02:28:43,788] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T04:00:00+00:00
[2021-08-19 02:28:43,857] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.306 seconds
[2021-08-19 02:29:14,770] {scheduler_job.py:181} INFO - Started process (PID=5809) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:29:14,777] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:29:14,781] {logging_mixin.py:104} INFO - [2021-08-19 02:29:14,780] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:29:14,814] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:29:14,863] {logging_mixin.py:104} INFO - [2021-08-19 02:29:14,862] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:29:14,899] {logging_mixin.py:104} INFO - [2021-08-19 02:29:14,899] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T04:00:00+00:00
[2021-08-19 02:29:14,920] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.159 seconds
[2021-08-19 02:29:44,975] {scheduler_job.py:181} INFO - Started process (PID=5863) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:29:44,980] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:29:44,982] {logging_mixin.py:104} INFO - [2021-08-19 02:29:44,982] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:29:45,014] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:29:45,076] {logging_mixin.py:104} INFO - [2021-08-19 02:29:45,076] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:29:45,118] {logging_mixin.py:104} INFO - [2021-08-19 02:29:45,118] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T04:00:00+00:00
[2021-08-19 02:29:45,153] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.190 seconds
[2021-08-19 02:30:15,222] {scheduler_job.py:181} INFO - Started process (PID=5915) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:30:15,225] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:30:15,226] {logging_mixin.py:104} INFO - [2021-08-19 02:30:15,226] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:30:15,260] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:30:15,313] {logging_mixin.py:104} INFO - [2021-08-19 02:30:15,313] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:30:15,348] {logging_mixin.py:104} INFO - [2021-08-19 02:30:15,348] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T04:00:00+00:00
[2021-08-19 02:30:15,375] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.163 seconds
[2021-08-19 02:30:45,606] {scheduler_job.py:181} INFO - Started process (PID=5969) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:30:45,610] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:30:45,612] {logging_mixin.py:104} INFO - [2021-08-19 02:30:45,612] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:30:45,636] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:30:45,686] {logging_mixin.py:104} INFO - [2021-08-19 02:30:45,685] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:30:45,715] {logging_mixin.py:104} INFO - [2021-08-19 02:30:45,715] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T04:00:00+00:00
[2021-08-19 02:30:45,739] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.140 seconds
[2021-08-19 02:31:15,874] {scheduler_job.py:181} INFO - Started process (PID=6022) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:31:15,876] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:31:15,878] {logging_mixin.py:104} INFO - [2021-08-19 02:31:15,877] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:31:15,907] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:31:15,957] {logging_mixin.py:104} INFO - [2021-08-19 02:31:15,957] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:31:15,986] {logging_mixin.py:104} INFO - [2021-08-19 02:31:15,986] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T04:00:00+00:00
[2021-08-19 02:31:16,011] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.144 seconds
[2021-08-19 02:31:46,375] {scheduler_job.py:181} INFO - Started process (PID=6076) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:31:46,379] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:31:46,380] {logging_mixin.py:104} INFO - [2021-08-19 02:31:46,380] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:31:46,397] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:31:46,436] {logging_mixin.py:104} INFO - [2021-08-19 02:31:46,435] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:31:46,461] {logging_mixin.py:104} INFO - [2021-08-19 02:31:46,461] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T04:00:00+00:00
[2021-08-19 02:31:46,484] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.116 seconds
[2021-08-19 02:32:16,903] {scheduler_job.py:181} INFO - Started process (PID=6128) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:32:16,905] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:32:16,907] {logging_mixin.py:104} INFO - [2021-08-19 02:32:16,906] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:32:16,942] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:32:17,006] {logging_mixin.py:104} INFO - [2021-08-19 02:32:17,005] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:32:17,049] {logging_mixin.py:104} INFO - [2021-08-19 02:32:17,049] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T04:00:00+00:00
[2021-08-19 02:32:17,085] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.194 seconds
[2021-08-19 02:32:47,142] {scheduler_job.py:181} INFO - Started process (PID=6185) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:32:47,151] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:32:47,155] {logging_mixin.py:104} INFO - [2021-08-19 02:32:47,155] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:32:47,196] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:32:47,258] {logging_mixin.py:104} INFO - [2021-08-19 02:32:47,258] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:32:47,295] {logging_mixin.py:104} INFO - [2021-08-19 02:32:47,295] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T04:00:00+00:00
[2021-08-19 02:32:47,330] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.208 seconds
[2021-08-19 02:33:17,879] {scheduler_job.py:181} INFO - Started process (PID=6251) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:33:17,883] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:33:17,884] {logging_mixin.py:104} INFO - [2021-08-19 02:33:17,884] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:33:17,915] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:33:17,966] {logging_mixin.py:104} INFO - [2021-08-19 02:33:17,966] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:33:18,004] {logging_mixin.py:104} INFO - [2021-08-19 02:33:18,003] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T07:15:00+00:00
[2021-08-19 02:33:18,036] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.167 seconds
[2021-08-19 02:33:48,353] {scheduler_job.py:181} INFO - Started process (PID=6304) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:33:48,356] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:33:48,358] {logging_mixin.py:104} INFO - [2021-08-19 02:33:48,357] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:33:48,381] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:33:48,423] {logging_mixin.py:104} INFO - [2021-08-19 02:33:48,423] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:33:48,449] {logging_mixin.py:104} INFO - [2021-08-19 02:33:48,449] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T08:00:00+00:00
[2021-08-19 02:33:48,475] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.132 seconds
[2021-08-19 02:34:18,961] {scheduler_job.py:181} INFO - Started process (PID=6366) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:34:18,964] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:34:18,966] {logging_mixin.py:104} INFO - [2021-08-19 02:34:18,966] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:34:18,999] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:34:19,071] {logging_mixin.py:104} INFO - [2021-08-19 02:34:19,070] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:34:19,113] {logging_mixin.py:104} INFO - [2021-08-19 02:34:19,113] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T08:00:00+00:00
[2021-08-19 02:34:19,143] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.193 seconds
[2021-08-19 02:34:49,453] {scheduler_job.py:181} INFO - Started process (PID=6420) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:34:49,454] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:34:49,455] {logging_mixin.py:104} INFO - [2021-08-19 02:34:49,455] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:34:49,480] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:34:49,541] {logging_mixin.py:104} INFO - [2021-08-19 02:34:49,540] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:34:49,576] {logging_mixin.py:104} INFO - [2021-08-19 02:34:49,576] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T08:00:00+00:00
[2021-08-19 02:34:49,605] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.159 seconds
[2021-08-19 02:35:19,764] {scheduler_job.py:181} INFO - Started process (PID=6474) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:35:19,770] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:35:19,772] {logging_mixin.py:104} INFO - [2021-08-19 02:35:19,771] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:35:19,811] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:35:19,875] {logging_mixin.py:104} INFO - [2021-08-19 02:35:19,875] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:35:19,916] {logging_mixin.py:104} INFO - [2021-08-19 02:35:19,915] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T08:00:00+00:00
[2021-08-19 02:35:19,945] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.190 seconds
[2021-08-19 02:35:50,261] {scheduler_job.py:181} INFO - Started process (PID=6525) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:35:50,263] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:35:50,264] {logging_mixin.py:104} INFO - [2021-08-19 02:35:50,264] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:35:50,287] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:35:50,341] {logging_mixin.py:104} INFO - [2021-08-19 02:35:50,341] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:35:50,377] {logging_mixin.py:104} INFO - [2021-08-19 02:35:50,376] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T08:00:00+00:00
[2021-08-19 02:35:50,401] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.148 seconds
[2021-08-19 02:36:20,879] {scheduler_job.py:181} INFO - Started process (PID=6577) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:36:20,882] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:36:20,883] {logging_mixin.py:104} INFO - [2021-08-19 02:36:20,883] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:36:20,904] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:36:20,959] {logging_mixin.py:104} INFO - [2021-08-19 02:36:20,959] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:36:20,994] {logging_mixin.py:104} INFO - [2021-08-19 02:36:20,994] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T08:00:00+00:00
[2021-08-19 02:36:21,020] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.149 seconds
[2021-08-19 02:36:51,138] {scheduler_job.py:181} INFO - Started process (PID=6631) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:36:51,142] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:36:51,143] {logging_mixin.py:104} INFO - [2021-08-19 02:36:51,143] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:36:51,179] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:36:51,230] {logging_mixin.py:104} INFO - [2021-08-19 02:36:51,230] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:36:51,263] {logging_mixin.py:104} INFO - [2021-08-19 02:36:51,263] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T08:00:00+00:00
[2021-08-19 02:36:51,289] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.160 seconds
[2021-08-19 02:37:21,360] {scheduler_job.py:181} INFO - Started process (PID=6694) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:37:21,363] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:37:21,365] {logging_mixin.py:104} INFO - [2021-08-19 02:37:21,365] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:37:21,401] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:37:21,462] {logging_mixin.py:104} INFO - [2021-08-19 02:37:21,461] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:37:21,501] {logging_mixin.py:104} INFO - [2021-08-19 02:37:21,501] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T08:00:00+00:00
[2021-08-19 02:37:21,534] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.185 seconds
[2021-08-19 02:37:51,743] {scheduler_job.py:181} INFO - Started process (PID=6754) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:37:51,748] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:37:51,750] {logging_mixin.py:104} INFO - [2021-08-19 02:37:51,750] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:37:51,795] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:37:51,856] {logging_mixin.py:104} INFO - [2021-08-19 02:37:51,856] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:37:51,899] {logging_mixin.py:104} INFO - [2021-08-19 02:37:51,899] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T08:00:00+00:00
[2021-08-19 02:37:51,928] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.204 seconds
[2021-08-19 02:38:22,040] {scheduler_job.py:181} INFO - Started process (PID=6823) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:38:22,050] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:38:22,051] {logging_mixin.py:104} INFO - [2021-08-19 02:38:22,051] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:38:22,080] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:38:22,132] {logging_mixin.py:104} INFO - [2021-08-19 02:38:22,132] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:38:22,171] {logging_mixin.py:104} INFO - [2021-08-19 02:38:22,171] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T08:00:00+00:00
[2021-08-19 02:38:22,200] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.169 seconds
[2021-08-19 02:38:52,258] {scheduler_job.py:181} INFO - Started process (PID=6878) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:38:52,262] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:38:52,263] {logging_mixin.py:104} INFO - [2021-08-19 02:38:52,263] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:38:52,290] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:38:52,341] {logging_mixin.py:104} INFO - [2021-08-19 02:38:52,341] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:38:52,375] {logging_mixin.py:104} INFO - [2021-08-19 02:38:52,374] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T12:00:00+00:00
[2021-08-19 02:38:52,400] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.149 seconds
[2021-08-19 02:39:22,546] {scheduler_job.py:181} INFO - Started process (PID=6931) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:39:22,550] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:39:22,552] {logging_mixin.py:104} INFO - [2021-08-19 02:39:22,551] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:39:22,577] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:39:22,627] {logging_mixin.py:104} INFO - [2021-08-19 02:39:22,627] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:39:22,660] {logging_mixin.py:104} INFO - [2021-08-19 02:39:22,660] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T12:00:00+00:00
[2021-08-19 02:39:22,684] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.146 seconds
[2021-08-19 02:39:53,011] {scheduler_job.py:181} INFO - Started process (PID=6984) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:39:53,014] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:39:53,016] {logging_mixin.py:104} INFO - [2021-08-19 02:39:53,016] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:39:53,056] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:39:53,134] {logging_mixin.py:104} INFO - [2021-08-19 02:39:53,134] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:39:53,184] {logging_mixin.py:104} INFO - [2021-08-19 02:39:53,184] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T12:00:00+00:00
[2021-08-19 02:39:53,217] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.218 seconds
[2021-08-19 02:40:23,790] {scheduler_job.py:181} INFO - Started process (PID=7037) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:40:23,796] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:40:23,799] {logging_mixin.py:104} INFO - [2021-08-19 02:40:23,799] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:40:23,843] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:40:23,981] {logging_mixin.py:104} INFO - [2021-08-19 02:40:23,980] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:40:24,021] {logging_mixin.py:104} INFO - [2021-08-19 02:40:24,021] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T12:00:00+00:00
[2021-08-19 02:40:24,051] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.272 seconds
[2021-08-19 02:40:54,182] {scheduler_job.py:181} INFO - Started process (PID=7091) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:40:54,191] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:40:54,193] {logging_mixin.py:104} INFO - [2021-08-19 02:40:54,193] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:40:54,247] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:40:54,333] {logging_mixin.py:104} INFO - [2021-08-19 02:40:54,332] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:40:54,377] {logging_mixin.py:104} INFO - [2021-08-19 02:40:54,377] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T12:00:00+00:00
[2021-08-19 02:40:54,413] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.243 seconds
[2021-08-19 02:41:24,931] {scheduler_job.py:181} INFO - Started process (PID=7147) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:41:24,934] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:41:24,936] {logging_mixin.py:104} INFO - [2021-08-19 02:41:24,935] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:41:24,979] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:41:25,047] {logging_mixin.py:104} INFO - [2021-08-19 02:41:25,047] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:41:25,112] {logging_mixin.py:104} INFO - [2021-08-19 02:41:25,111] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T12:00:00+00:00
[2021-08-19 02:41:25,150] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.232 seconds
[2021-08-19 02:41:55,221] {scheduler_job.py:181} INFO - Started process (PID=7201) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:41:55,226] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:41:55,234] {logging_mixin.py:104} INFO - [2021-08-19 02:41:55,233] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:41:55,285] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:41:55,376] {logging_mixin.py:104} INFO - [2021-08-19 02:41:55,376] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:41:55,427] {logging_mixin.py:104} INFO - [2021-08-19 02:41:55,427] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T12:00:00+00:00
[2021-08-19 02:41:55,459] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.252 seconds
[2021-08-19 02:42:25,557] {scheduler_job.py:181} INFO - Started process (PID=7252) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:42:25,562] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:42:25,564] {logging_mixin.py:104} INFO - [2021-08-19 02:42:25,564] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:42:25,615] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:42:25,726] {logging_mixin.py:104} INFO - [2021-08-19 02:42:25,726] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:42:25,788] {logging_mixin.py:104} INFO - [2021-08-19 02:42:25,787] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T12:00:00+00:00
[2021-08-19 02:42:25,824] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.286 seconds
[2021-08-19 02:42:55,899] {scheduler_job.py:181} INFO - Started process (PID=7306) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:42:55,901] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:42:55,902] {logging_mixin.py:104} INFO - [2021-08-19 02:42:55,902] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:42:55,920] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:42:55,964] {logging_mixin.py:104} INFO - [2021-08-19 02:42:55,964] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:42:55,986] {logging_mixin.py:104} INFO - [2021-08-19 02:42:55,986] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T12:00:00+00:00
[2021-08-19 02:42:56,014] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.122 seconds
[2021-08-19 02:43:26,574] {scheduler_job.py:181} INFO - Started process (PID=7364) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:43:26,580] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:43:26,582] {logging_mixin.py:104} INFO - [2021-08-19 02:43:26,581] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:43:26,644] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:43:26,792] {logging_mixin.py:104} INFO - [2021-08-19 02:43:26,791] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:43:26,852] {logging_mixin.py:104} INFO - [2021-08-19 02:43:26,852] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T12:00:00+00:00
[2021-08-19 02:43:26,895] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.332 seconds
[2021-08-19 02:43:57,313] {scheduler_job.py:181} INFO - Started process (PID=7437) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:43:57,316] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:43:57,318] {logging_mixin.py:104} INFO - [2021-08-19 02:43:57,318] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:43:57,357] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:43:57,420] {logging_mixin.py:104} INFO - [2021-08-19 02:43:57,420] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:43:57,462] {logging_mixin.py:104} INFO - [2021-08-19 02:43:57,462] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T12:00:00+00:00
[2021-08-19 02:43:57,485] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.184 seconds
[2021-08-19 02:44:27,925] {scheduler_job.py:181} INFO - Started process (PID=7491) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:44:27,929] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:44:27,932] {logging_mixin.py:104} INFO - [2021-08-19 02:44:27,931] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:44:27,964] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:44:28,031] {logging_mixin.py:104} INFO - [2021-08-19 02:44:28,031] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:44:28,072] {logging_mixin.py:104} INFO - [2021-08-19 02:44:28,072] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T16:00:00+00:00
[2021-08-19 02:44:28,105] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.189 seconds
[2021-08-19 02:44:58,183] {scheduler_job.py:181} INFO - Started process (PID=7544) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:44:58,191] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:44:58,193] {logging_mixin.py:104} INFO - [2021-08-19 02:44:58,193] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:44:58,236] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:44:58,303] {logging_mixin.py:104} INFO - [2021-08-19 02:44:58,301] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:44:58,345] {logging_mixin.py:104} INFO - [2021-08-19 02:44:58,344] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T16:00:00+00:00
[2021-08-19 02:44:58,375] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.200 seconds
[2021-08-19 02:45:28,660] {scheduler_job.py:181} INFO - Started process (PID=7597) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:45:28,663] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:45:28,664] {logging_mixin.py:104} INFO - [2021-08-19 02:45:28,664] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:45:28,695] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:45:28,766] {logging_mixin.py:104} INFO - [2021-08-19 02:45:28,766] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:45:28,803] {logging_mixin.py:104} INFO - [2021-08-19 02:45:28,802] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T16:00:00+00:00
[2021-08-19 02:45:28,836] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.189 seconds
[2021-08-19 02:45:59,085] {scheduler_job.py:181} INFO - Started process (PID=7649) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:45:59,088] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:45:59,090] {logging_mixin.py:104} INFO - [2021-08-19 02:45:59,090] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:45:59,123] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:45:59,189] {logging_mixin.py:104} INFO - [2021-08-19 02:45:59,188] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:45:59,223] {logging_mixin.py:104} INFO - [2021-08-19 02:45:59,222] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T16:00:00+00:00
[2021-08-19 02:45:59,245] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.170 seconds
[2021-08-19 02:46:29,296] {scheduler_job.py:181} INFO - Started process (PID=7703) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:46:29,298] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:46:29,299] {logging_mixin.py:104} INFO - [2021-08-19 02:46:29,299] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:46:29,318] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:46:29,367] {logging_mixin.py:104} INFO - [2021-08-19 02:46:29,367] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:46:29,396] {logging_mixin.py:104} INFO - [2021-08-19 02:46:29,395] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T16:00:00+00:00
[2021-08-19 02:46:29,419] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.132 seconds
[2021-08-19 02:46:59,765] {scheduler_job.py:181} INFO - Started process (PID=7766) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:46:59,769] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:46:59,770] {logging_mixin.py:104} INFO - [2021-08-19 02:46:59,770] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:46:59,798] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:46:59,845] {logging_mixin.py:104} INFO - [2021-08-19 02:46:59,845] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:46:59,882] {logging_mixin.py:104} INFO - [2021-08-19 02:46:59,882] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T16:00:00+00:00
[2021-08-19 02:46:59,907] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.151 seconds
[2021-08-19 02:47:30,387] {scheduler_job.py:181} INFO - Started process (PID=7820) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:47:30,390] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:47:30,391] {logging_mixin.py:104} INFO - [2021-08-19 02:47:30,391] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:47:30,407] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:47:30,446] {logging_mixin.py:104} INFO - [2021-08-19 02:47:30,446] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:47:30,469] {logging_mixin.py:104} INFO - [2021-08-19 02:47:30,469] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T16:00:00+00:00
[2021-08-19 02:47:30,493] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.112 seconds
[2021-08-19 02:48:01,172] {scheduler_job.py:181} INFO - Started process (PID=7873) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:48:01,176] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:48:01,177] {logging_mixin.py:104} INFO - [2021-08-19 02:48:01,177] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:48:01,200] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:48:01,251] {logging_mixin.py:104} INFO - [2021-08-19 02:48:01,250] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:48:01,278] {logging_mixin.py:104} INFO - [2021-08-19 02:48:01,278] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T16:00:00+00:00
[2021-08-19 02:48:01,301] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.136 seconds
[2021-08-19 02:48:31,690] {scheduler_job.py:181} INFO - Started process (PID=7925) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:48:31,693] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:48:31,693] {logging_mixin.py:104} INFO - [2021-08-19 02:48:31,693] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:48:31,709] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:48:31,749] {logging_mixin.py:104} INFO - [2021-08-19 02:48:31,749] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:48:31,772] {logging_mixin.py:104} INFO - [2021-08-19 02:48:31,772] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T16:00:00+00:00
[2021-08-19 02:48:31,792] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.108 seconds
[2021-08-19 02:49:02,446] {scheduler_job.py:181} INFO - Started process (PID=7991) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:49:02,450] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:49:02,455] {logging_mixin.py:104} INFO - [2021-08-19 02:49:02,455] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:49:02,518] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:49:02,641] {logging_mixin.py:104} INFO - [2021-08-19 02:49:02,640] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:49:02,701] {logging_mixin.py:104} INFO - [2021-08-19 02:49:02,700] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T16:00:00+00:00
[2021-08-19 02:49:02,763] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.342 seconds
[2021-08-19 02:49:32,895] {scheduler_job.py:181} INFO - Started process (PID=8063) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:49:32,899] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:49:32,902] {logging_mixin.py:104} INFO - [2021-08-19 02:49:32,902] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:49:32,950] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:49:33,019] {logging_mixin.py:104} INFO - [2021-08-19 02:49:33,018] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:49:33,082] {logging_mixin.py:104} INFO - [2021-08-19 02:49:33,082] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T16:00:00+00:00
[2021-08-19 02:49:33,119] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.236 seconds
[2021-08-19 02:50:03,997] {scheduler_job.py:181} INFO - Started process (PID=8109) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:50:04,003] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:50:04,006] {logging_mixin.py:104} INFO - [2021-08-19 02:50:04,005] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:50:04,044] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:50:04,134] {logging_mixin.py:104} INFO - [2021-08-19 02:50:04,133] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:50:04,191] {logging_mixin.py:104} INFO - [2021-08-19 02:50:04,191] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T20:00:00+00:00
[2021-08-19 02:50:04,224] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.243 seconds
[2021-08-19 02:50:35,058] {scheduler_job.py:181} INFO - Started process (PID=8163) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:50:35,059] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:50:35,060] {logging_mixin.py:104} INFO - [2021-08-19 02:50:35,059] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:50:35,068] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:50:35,093] {logging_mixin.py:104} INFO - [2021-08-19 02:50:35,093] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:50:35,108] {logging_mixin.py:104} INFO - [2021-08-19 02:50:35,107] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T20:00:00+00:00
[2021-08-19 02:50:35,121] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.067 seconds
[2021-08-19 02:51:05,694] {scheduler_job.py:181} INFO - Started process (PID=8226) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:51:05,695] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:51:05,696] {logging_mixin.py:104} INFO - [2021-08-19 02:51:05,696] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:51:05,705] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:51:05,723] {logging_mixin.py:104} INFO - [2021-08-19 02:51:05,723] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:51:05,735] {logging_mixin.py:104} INFO - [2021-08-19 02:51:05,734] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T20:00:00+00:00
[2021-08-19 02:51:05,746] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.054 seconds
[2021-08-19 02:51:36,262] {scheduler_job.py:181} INFO - Started process (PID=8289) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:51:36,264] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:51:36,264] {logging_mixin.py:104} INFO - [2021-08-19 02:51:36,264] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:51:36,275] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:51:36,298] {logging_mixin.py:104} INFO - [2021-08-19 02:51:36,297] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:51:36,316] {logging_mixin.py:104} INFO - [2021-08-19 02:51:36,316] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T20:00:00+00:00
[2021-08-19 02:51:36,330] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.071 seconds
[2021-08-19 02:52:06,792] {scheduler_job.py:181} INFO - Started process (PID=8342) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:52:06,793] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:52:06,794] {logging_mixin.py:104} INFO - [2021-08-19 02:52:06,794] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:52:06,806] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:52:06,830] {logging_mixin.py:104} INFO - [2021-08-19 02:52:06,830] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:52:06,844] {logging_mixin.py:104} INFO - [2021-08-19 02:52:06,844] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T20:00:00+00:00
[2021-08-19 02:52:06,857] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.069 seconds
[2021-08-19 02:52:36,973] {scheduler_job.py:181} INFO - Started process (PID=8407) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:52:36,976] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:52:36,977] {logging_mixin.py:104} INFO - [2021-08-19 02:52:36,977] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:52:36,996] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:52:37,034] {logging_mixin.py:104} INFO - [2021-08-19 02:52:37,034] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:52:37,061] {logging_mixin.py:104} INFO - [2021-08-19 02:52:37,061] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T20:00:00+00:00
[2021-08-19 02:52:37,084] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.117 seconds
[2021-08-19 02:53:07,463] {scheduler_job.py:181} INFO - Started process (PID=8460) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:53:07,464] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:53:07,465] {logging_mixin.py:104} INFO - [2021-08-19 02:53:07,465] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:53:07,477] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:53:07,495] {logging_mixin.py:104} INFO - [2021-08-19 02:53:07,495] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:53:07,506] {logging_mixin.py:104} INFO - [2021-08-19 02:53:07,506] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T20:00:00+00:00
[2021-08-19 02:53:07,517] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.057 seconds
[2021-08-19 02:53:37,724] {scheduler_job.py:181} INFO - Started process (PID=8523) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:53:37,729] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:53:37,731] {logging_mixin.py:104} INFO - [2021-08-19 02:53:37,731] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:53:37,755] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:53:37,797] {logging_mixin.py:104} INFO - [2021-08-19 02:53:37,797] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:53:37,826] {logging_mixin.py:104} INFO - [2021-08-19 02:53:37,826] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T20:00:00+00:00
[2021-08-19 02:53:37,842] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.122 seconds
[2021-08-19 02:54:08,493] {scheduler_job.py:181} INFO - Started process (PID=8576) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:54:08,494] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:54:08,495] {logging_mixin.py:104} INFO - [2021-08-19 02:54:08,495] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:54:08,506] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:54:08,528] {logging_mixin.py:104} INFO - [2021-08-19 02:54:08,527] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:54:08,545] {logging_mixin.py:104} INFO - [2021-08-19 02:54:08,544] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T20:00:00+00:00
[2021-08-19 02:54:08,558] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.068 seconds
[2021-08-19 02:54:38,943] {scheduler_job.py:181} INFO - Started process (PID=8643) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:54:38,945] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:54:38,946] {logging_mixin.py:104} INFO - [2021-08-19 02:54:38,946] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:54:38,967] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:54:39,012] {logging_mixin.py:104} INFO - [2021-08-19 02:54:39,012] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:54:39,037] {logging_mixin.py:104} INFO - [2021-08-19 02:54:39,037] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T20:00:00+00:00
[2021-08-19 02:54:39,056] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.120 seconds
[2021-08-19 02:55:09,336] {scheduler_job.py:181} INFO - Started process (PID=8703) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:55:09,338] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:55:09,338] {logging_mixin.py:104} INFO - [2021-08-19 02:55:09,338] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:55:09,352] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:55:09,377] {logging_mixin.py:104} INFO - [2021-08-19 02:55:09,377] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:55:09,396] {logging_mixin.py:104} INFO - [2021-08-19 02:55:09,396] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-18T20:00:00+00:00
[2021-08-19 02:55:09,412] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.080 seconds
[2021-08-19 02:55:39,901] {scheduler_job.py:181} INFO - Started process (PID=8767) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:55:39,903] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:55:39,903] {logging_mixin.py:104} INFO - [2021-08-19 02:55:39,903] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:55:39,918] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:55:39,948] {logging_mixin.py:104} INFO - [2021-08-19 02:55:39,948] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:55:39,964] {logging_mixin.py:104} INFO - [2021-08-19 02:55:39,964] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T00:00:00+00:00
[2021-08-19 02:55:39,977] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.080 seconds
[2021-08-19 02:56:10,375] {scheduler_job.py:181} INFO - Started process (PID=8820) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:56:10,377] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:56:10,378] {logging_mixin.py:104} INFO - [2021-08-19 02:56:10,377] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:56:10,392] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:56:10,422] {logging_mixin.py:104} INFO - [2021-08-19 02:56:10,421] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:56:10,445] {logging_mixin.py:104} INFO - [2021-08-19 02:56:10,445] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T00:00:00+00:00
[2021-08-19 02:56:10,458] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.088 seconds
[2021-08-19 02:56:40,902] {scheduler_job.py:181} INFO - Started process (PID=8883) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:56:40,904] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:56:40,905] {logging_mixin.py:104} INFO - [2021-08-19 02:56:40,905] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:56:40,919] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:56:40,946] {logging_mixin.py:104} INFO - [2021-08-19 02:56:40,946] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:56:40,965] {logging_mixin.py:104} INFO - [2021-08-19 02:56:40,965] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T00:00:00+00:00
[2021-08-19 02:56:40,980] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.081 seconds
[2021-08-19 02:57:11,375] {scheduler_job.py:181} INFO - Started process (PID=8935) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:57:11,376] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:57:11,377] {logging_mixin.py:104} INFO - [2021-08-19 02:57:11,377] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:57:11,386] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:57:11,407] {logging_mixin.py:104} INFO - [2021-08-19 02:57:11,407] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:57:11,418] {logging_mixin.py:104} INFO - [2021-08-19 02:57:11,418] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T00:00:00+00:00
[2021-08-19 02:57:11,430] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.057 seconds
[2021-08-19 02:57:42,076] {scheduler_job.py:181} INFO - Started process (PID=8998) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:57:42,078] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:57:42,079] {logging_mixin.py:104} INFO - [2021-08-19 02:57:42,079] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:57:42,095] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:57:42,122] {logging_mixin.py:104} INFO - [2021-08-19 02:57:42,122] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:57:42,139] {logging_mixin.py:104} INFO - [2021-08-19 02:57:42,139] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T00:00:00+00:00
[2021-08-19 02:57:42,155] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.082 seconds
[2021-08-19 02:58:12,651] {scheduler_job.py:181} INFO - Started process (PID=9051) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:58:12,652] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:58:12,653] {logging_mixin.py:104} INFO - [2021-08-19 02:58:12,653] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:58:12,662] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:58:12,680] {logging_mixin.py:104} INFO - [2021-08-19 02:58:12,680] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:58:12,694] {logging_mixin.py:104} INFO - [2021-08-19 02:58:12,694] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T00:00:00+00:00
[2021-08-19 02:58:12,704] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.056 seconds
[2021-08-19 02:58:43,219] {scheduler_job.py:181} INFO - Started process (PID=9114) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:58:43,221] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:58:43,221] {logging_mixin.py:104} INFO - [2021-08-19 02:58:43,221] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:58:43,233] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:58:43,257] {logging_mixin.py:104} INFO - [2021-08-19 02:58:43,257] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:58:43,276] {logging_mixin.py:104} INFO - [2021-08-19 02:58:43,276] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T00:00:00+00:00
[2021-08-19 02:58:43,297] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.081 seconds
[2021-08-19 02:59:13,606] {scheduler_job.py:181} INFO - Started process (PID=9166) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:59:13,607] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:59:13,608] {logging_mixin.py:104} INFO - [2021-08-19 02:59:13,608] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:59:13,619] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:59:13,642] {logging_mixin.py:104} INFO - [2021-08-19 02:59:13,642] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:59:13,656] {logging_mixin.py:104} INFO - [2021-08-19 02:59:13,656] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T00:00:00+00:00
[2021-08-19 02:59:13,668] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.065 seconds
[2021-08-19 02:59:43,846] {scheduler_job.py:181} INFO - Started process (PID=9230) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 02:59:43,847] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 02:59:43,847] {logging_mixin.py:104} INFO - [2021-08-19 02:59:43,847] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:59:43,857] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 02:59:43,880] {logging_mixin.py:104} INFO - [2021-08-19 02:59:43,879] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 02:59:43,894] {logging_mixin.py:104} INFO - [2021-08-19 02:59:43,894] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T00:00:00+00:00
[2021-08-19 02:59:43,906] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.063 seconds
[2021-08-19 03:00:14,402] {scheduler_job.py:181} INFO - Started process (PID=9304) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:00:14,405] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:00:14,406] {logging_mixin.py:104} INFO - [2021-08-19 03:00:14,406] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:00:14,436] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:00:14,511] {logging_mixin.py:104} INFO - [2021-08-19 03:00:14,511] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:00:14,549] {logging_mixin.py:104} INFO - [2021-08-19 03:00:14,548] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T00:00:00+00:00
[2021-08-19 03:00:14,575] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.182 seconds
[2021-08-19 03:00:45,003] {scheduler_job.py:181} INFO - Started process (PID=9381) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:00:45,004] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:00:45,004] {logging_mixin.py:104} INFO - [2021-08-19 03:00:45,004] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:00:45,012] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:00:45,030] {logging_mixin.py:104} INFO - [2021-08-19 03:00:45,030] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:00:45,042] {logging_mixin.py:104} INFO - [2021-08-19 03:00:45,042] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:00:00+00:00
[2021-08-19 03:00:45,053] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.052 seconds
[2021-08-19 03:01:15,209] {scheduler_job.py:181} INFO - Started process (PID=9433) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:01:15,210] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:01:15,210] {logging_mixin.py:104} INFO - [2021-08-19 03:01:15,210] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:01:15,221] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:01:15,241] {logging_mixin.py:104} INFO - [2021-08-19 03:01:15,241] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:01:15,252] {logging_mixin.py:104} INFO - [2021-08-19 03:01:15,251] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:00:00+00:00
[2021-08-19 03:01:15,263] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.056 seconds
[2021-08-19 03:01:45,941] {scheduler_job.py:181} INFO - Started process (PID=9497) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:01:45,943] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:01:45,943] {logging_mixin.py:104} INFO - [2021-08-19 03:01:45,943] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:01:45,954] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:01:45,975] {logging_mixin.py:104} INFO - [2021-08-19 03:01:45,975] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:01:45,988] {logging_mixin.py:104} INFO - [2021-08-19 03:01:45,988] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:00:00+00:00
[2021-08-19 03:01:46,000] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.062 seconds
[2021-08-19 03:02:16,198] {scheduler_job.py:181} INFO - Started process (PID=9550) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:02:16,199] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:02:16,199] {logging_mixin.py:104} INFO - [2021-08-19 03:02:16,199] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:02:16,208] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:02:16,227] {logging_mixin.py:104} INFO - [2021-08-19 03:02:16,227] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:02:16,238] {logging_mixin.py:104} INFO - [2021-08-19 03:02:16,238] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:00:00+00:00
[2021-08-19 03:02:16,249] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.053 seconds
[2021-08-19 03:02:46,601] {scheduler_job.py:181} INFO - Started process (PID=9614) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:02:46,602] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:02:46,603] {logging_mixin.py:104} INFO - [2021-08-19 03:02:46,603] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:02:46,613] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:02:46,635] {logging_mixin.py:104} INFO - [2021-08-19 03:02:46,635] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:02:46,648] {logging_mixin.py:104} INFO - [2021-08-19 03:02:46,648] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:00:00+00:00
[2021-08-19 03:02:46,659] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.061 seconds
[2021-08-19 03:03:17,442] {scheduler_job.py:181} INFO - Started process (PID=9677) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:03:17,443] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:03:17,444] {logging_mixin.py:104} INFO - [2021-08-19 03:03:17,444] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:03:17,453] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:03:17,472] {logging_mixin.py:104} INFO - [2021-08-19 03:03:17,472] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:03:17,484] {logging_mixin.py:104} INFO - [2021-08-19 03:03:17,484] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:00:00+00:00
[2021-08-19 03:03:17,493] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.053 seconds
[2021-08-19 03:03:48,337] {scheduler_job.py:181} INFO - Started process (PID=9730) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:03:48,338] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:03:48,339] {logging_mixin.py:104} INFO - [2021-08-19 03:03:48,339] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:03:48,346] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:03:48,364] {logging_mixin.py:104} INFO - [2021-08-19 03:03:48,363] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:03:48,375] {logging_mixin.py:104} INFO - [2021-08-19 03:03:48,375] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:00:00+00:00
[2021-08-19 03:03:48,385] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.051 seconds
[2021-08-19 03:04:18,451] {scheduler_job.py:181} INFO - Started process (PID=9793) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:04:18,452] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:04:18,453] {logging_mixin.py:104} INFO - [2021-08-19 03:04:18,453] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:04:18,463] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:04:18,484] {logging_mixin.py:104} INFO - [2021-08-19 03:04:18,483] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:04:18,497] {logging_mixin.py:104} INFO - [2021-08-19 03:04:18,497] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:00:00+00:00
[2021-08-19 03:04:18,509] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.061 seconds
[2021-08-19 03:04:49,420] {scheduler_job.py:181} INFO - Started process (PID=9845) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:04:49,422] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:04:49,422] {logging_mixin.py:104} INFO - [2021-08-19 03:04:49,422] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:04:49,435] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:04:49,462] {logging_mixin.py:104} INFO - [2021-08-19 03:04:49,462] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:04:49,487] {logging_mixin.py:104} INFO - [2021-08-19 03:04:49,487] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:00:00+00:00
[2021-08-19 03:04:49,502] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.086 seconds
[2021-08-19 03:05:20,461] {scheduler_job.py:181} INFO - Started process (PID=9916) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:05:20,463] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:05:20,465] {logging_mixin.py:104} INFO - [2021-08-19 03:05:20,465] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:05:20,495] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:05:20,618] {logging_mixin.py:104} INFO - [2021-08-19 03:05:20,618] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:05:20,663] {logging_mixin.py:104} INFO - [2021-08-19 03:05:20,663] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:00:00+00:00
[2021-08-19 03:05:20,703] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.253 seconds
[2021-08-19 03:05:51,108] {scheduler_job.py:181} INFO - Started process (PID=9978) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:05:51,110] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:05:51,111] {logging_mixin.py:104} INFO - [2021-08-19 03:05:51,111] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:05:51,127] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:05:51,159] {logging_mixin.py:104} INFO - [2021-08-19 03:05:51,159] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:05:51,182] {logging_mixin.py:104} INFO - [2021-08-19 03:05:51,182] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:00:00+00:00
[2021-08-19 03:05:51,200] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.096 seconds
[2021-08-19 03:06:21,285] {scheduler_job.py:181} INFO - Started process (PID=10041) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:06:21,286] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:06:21,287] {logging_mixin.py:104} INFO - [2021-08-19 03:06:21,287] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:06:21,299] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:06:21,325] {logging_mixin.py:104} INFO - [2021-08-19 03:06:21,325] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:06:21,340] {logging_mixin.py:104} INFO - [2021-08-19 03:06:21,339] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:00:00+00:00
[2021-08-19 03:06:21,352] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.071 seconds
[2021-08-19 03:06:51,630] {scheduler_job.py:181} INFO - Started process (PID=10093) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:06:51,631] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:06:51,632] {logging_mixin.py:104} INFO - [2021-08-19 03:06:51,632] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:06:51,640] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:06:51,659] {logging_mixin.py:104} INFO - [2021-08-19 03:06:51,659] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:06:51,669] {logging_mixin.py:104} INFO - [2021-08-19 03:06:51,669] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:00:00+00:00
[2021-08-19 03:06:51,679] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.051 seconds
[2021-08-19 03:07:21,922] {scheduler_job.py:181} INFO - Started process (PID=10156) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:07:21,923] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:07:21,923] {logging_mixin.py:104} INFO - [2021-08-19 03:07:21,923] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:07:21,931] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:07:21,950] {logging_mixin.py:104} INFO - [2021-08-19 03:07:21,950] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:07:21,960] {logging_mixin.py:104} INFO - [2021-08-19 03:07:21,960] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:00:00+00:00
[2021-08-19 03:07:21,971] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.052 seconds
[2021-08-19 03:07:52,400] {scheduler_job.py:181} INFO - Started process (PID=10220) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:07:52,401] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:07:52,401] {logging_mixin.py:104} INFO - [2021-08-19 03:07:52,401] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:07:52,410] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:07:52,428] {logging_mixin.py:104} INFO - [2021-08-19 03:07:52,428] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:07:52,439] {logging_mixin.py:104} INFO - [2021-08-19 03:07:52,439] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:00:00+00:00
[2021-08-19 03:07:52,452] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.055 seconds
[2021-08-19 03:08:22,952] {scheduler_job.py:181} INFO - Started process (PID=10283) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:08:22,954] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:08:22,955] {logging_mixin.py:104} INFO - [2021-08-19 03:08:22,954] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:08:22,968] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:08:22,996] {logging_mixin.py:104} INFO - [2021-08-19 03:08:22,996] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:08:23,010] {logging_mixin.py:104} INFO - [2021-08-19 03:08:23,010] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:00:00+00:00
[2021-08-19 03:08:23,020] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.073 seconds
[2021-08-19 03:08:53,136] {scheduler_job.py:181} INFO - Started process (PID=10335) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:08:53,137] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:08:53,137] {logging_mixin.py:104} INFO - [2021-08-19 03:08:53,137] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:08:53,145] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:08:53,164] {logging_mixin.py:104} INFO - [2021-08-19 03:08:53,163] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:08:53,174] {logging_mixin.py:104} INFO - [2021-08-19 03:08:53,174] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:00:00+00:00
[2021-08-19 03:08:53,183] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.051 seconds
[2021-08-19 03:09:23,448] {scheduler_job.py:181} INFO - Started process (PID=10399) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:09:23,449] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:09:23,450] {logging_mixin.py:104} INFO - [2021-08-19 03:09:23,450] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:09:23,473] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:09:23,511] {logging_mixin.py:104} INFO - [2021-08-19 03:09:23,511] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:09:23,538] {logging_mixin.py:104} INFO - [2021-08-19 03:09:23,537] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:00:00+00:00
[2021-08-19 03:09:23,561] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.118 seconds
[2021-08-19 03:09:54,451] {scheduler_job.py:181} INFO - Started process (PID=10462) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:09:54,452] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:09:54,453] {logging_mixin.py:104} INFO - [2021-08-19 03:09:54,453] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:09:54,461] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:09:54,480] {logging_mixin.py:104} INFO - [2021-08-19 03:09:54,480] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:09:54,491] {logging_mixin.py:104} INFO - [2021-08-19 03:09:54,491] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:00:00+00:00
[2021-08-19 03:09:54,501] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.053 seconds
[2021-08-19 03:10:24,979] {scheduler_job.py:181} INFO - Started process (PID=10516) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:10:24,980] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:10:24,980] {logging_mixin.py:104} INFO - [2021-08-19 03:10:24,980] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:10:24,990] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:10:25,010] {logging_mixin.py:104} INFO - [2021-08-19 03:10:25,010] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:10:25,022] {logging_mixin.py:104} INFO - [2021-08-19 03:10:25,022] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:00:00+00:00
[2021-08-19 03:10:25,032] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.057 seconds
[2021-08-19 03:10:55,453] {scheduler_job.py:181} INFO - Started process (PID=10579) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:10:55,454] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:10:55,455] {logging_mixin.py:104} INFO - [2021-08-19 03:10:55,454] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:10:55,463] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:10:55,481] {logging_mixin.py:104} INFO - [2021-08-19 03:10:55,481] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:10:55,493] {logging_mixin.py:104} INFO - [2021-08-19 03:10:55,492] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:00:00+00:00
[2021-08-19 03:10:55,504] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.053 seconds
[2021-08-19 03:11:25,886] {scheduler_job.py:181} INFO - Started process (PID=10641) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:11:25,887] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:11:25,888] {logging_mixin.py:104} INFO - [2021-08-19 03:11:25,887] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:11:25,896] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:11:25,914] {logging_mixin.py:104} INFO - [2021-08-19 03:11:25,914] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:11:25,925] {logging_mixin.py:104} INFO - [2021-08-19 03:11:25,925] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:00:00+00:00
[2021-08-19 03:11:25,936] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.053 seconds
[2021-08-19 03:11:56,459] {scheduler_job.py:181} INFO - Started process (PID=10696) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:11:56,460] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:11:56,460] {logging_mixin.py:104} INFO - [2021-08-19 03:11:56,460] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:11:56,469] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:11:56,488] {logging_mixin.py:104} INFO - [2021-08-19 03:11:56,488] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:11:56,499] {logging_mixin.py:104} INFO - [2021-08-19 03:11:56,499] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:00:00+00:00
[2021-08-19 03:11:56,511] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.055 seconds
[2021-08-19 03:12:26,709] {scheduler_job.py:181} INFO - Started process (PID=10758) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:12:26,710] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:12:26,711] {logging_mixin.py:104} INFO - [2021-08-19 03:12:26,711] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:12:26,720] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:12:26,737] {logging_mixin.py:104} INFO - [2021-08-19 03:12:26,737] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:12:26,749] {logging_mixin.py:104} INFO - [2021-08-19 03:12:26,749] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:00:00+00:00
[2021-08-19 03:12:26,764] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.058 seconds
[2021-08-19 03:12:57,182] {scheduler_job.py:181} INFO - Started process (PID=10821) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:12:57,183] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:12:57,184] {logging_mixin.py:104} INFO - [2021-08-19 03:12:57,183] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:12:57,194] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:12:57,213] {logging_mixin.py:104} INFO - [2021-08-19 03:12:57,213] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:12:57,226] {logging_mixin.py:104} INFO - [2021-08-19 03:12:57,226] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:00:00+00:00
[2021-08-19 03:12:57,238] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.059 seconds
[2021-08-19 03:13:27,709] {scheduler_job.py:181} INFO - Started process (PID=10874) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:13:27,710] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:13:27,711] {logging_mixin.py:104} INFO - [2021-08-19 03:13:27,711] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:13:27,719] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:13:27,738] {logging_mixin.py:104} INFO - [2021-08-19 03:13:27,738] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:13:27,749] {logging_mixin.py:104} INFO - [2021-08-19 03:13:27,749] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:00:00+00:00
[2021-08-19 03:13:27,761] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.056 seconds
[2021-08-19 03:13:58,369] {scheduler_job.py:181} INFO - Started process (PID=10936) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:13:58,370] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:13:58,370] {logging_mixin.py:104} INFO - [2021-08-19 03:13:58,370] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:13:58,378] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:13:58,397] {logging_mixin.py:104} INFO - [2021-08-19 03:13:58,396] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:13:58,407] {logging_mixin.py:104} INFO - [2021-08-19 03:13:58,407] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:00:00+00:00
[2021-08-19 03:13:58,418] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.052 seconds
[2021-08-19 03:14:28,942] {scheduler_job.py:181} INFO - Started process (PID=10999) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:14:28,943] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:14:28,944] {logging_mixin.py:104} INFO - [2021-08-19 03:14:28,944] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:14:28,955] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:14:28,975] {logging_mixin.py:104} INFO - [2021-08-19 03:14:28,975] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:14:28,986] {logging_mixin.py:104} INFO - [2021-08-19 03:14:28,986] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:00:00+00:00
[2021-08-19 03:14:28,997] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.060 seconds
[2021-08-19 03:14:59,940] {scheduler_job.py:181} INFO - Started process (PID=11051) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:14:59,941] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:14:59,942] {logging_mixin.py:104} INFO - [2021-08-19 03:14:59,941] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:14:59,950] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:14:59,969] {logging_mixin.py:104} INFO - [2021-08-19 03:14:59,969] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:14:59,981] {logging_mixin.py:104} INFO - [2021-08-19 03:14:59,981] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:00:00+00:00
[2021-08-19 03:14:59,992] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.054 seconds
[2021-08-19 03:15:30,479] {scheduler_job.py:181} INFO - Started process (PID=11114) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:15:30,480] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:15:30,480] {logging_mixin.py:104} INFO - [2021-08-19 03:15:30,480] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:15:30,490] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:15:30,512] {logging_mixin.py:104} INFO - [2021-08-19 03:15:30,512] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:15:30,526] {logging_mixin.py:104} INFO - [2021-08-19 03:15:30,526] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:15:00+00:00
[2021-08-19 03:15:30,539] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.063 seconds
[2021-08-19 03:16:01,234] {scheduler_job.py:181} INFO - Started process (PID=11174) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:16:01,235] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:16:01,236] {logging_mixin.py:104} INFO - [2021-08-19 03:16:01,236] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:16:01,257] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:16:01,287] {logging_mixin.py:104} INFO - [2021-08-19 03:16:01,287] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:16:01,309] {logging_mixin.py:104} INFO - [2021-08-19 03:16:01,308] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:15:00+00:00
[2021-08-19 03:16:01,325] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.096 seconds
[2021-08-19 03:16:31,369] {scheduler_job.py:181} INFO - Started process (PID=11229) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:16:31,370] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:16:31,371] {logging_mixin.py:104} INFO - [2021-08-19 03:16:31,371] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:16:31,380] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:16:31,400] {logging_mixin.py:104} INFO - [2021-08-19 03:16:31,399] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:16:31,410] {logging_mixin.py:104} INFO - [2021-08-19 03:16:31,410] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:15:00+00:00
[2021-08-19 03:16:31,422] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.055 seconds
[2021-08-19 03:17:01,996] {scheduler_job.py:181} INFO - Started process (PID=11292) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:17:01,997] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:17:01,998] {logging_mixin.py:104} INFO - [2021-08-19 03:17:01,998] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:17:02,008] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:17:02,026] {logging_mixin.py:104} INFO - [2021-08-19 03:17:02,026] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:17:02,037] {logging_mixin.py:104} INFO - [2021-08-19 03:17:02,037] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:15:00+00:00
[2021-08-19 03:17:02,047] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.053 seconds
[2021-08-19 03:17:32,389] {scheduler_job.py:181} INFO - Started process (PID=11345) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:17:32,390] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:17:32,391] {logging_mixin.py:104} INFO - [2021-08-19 03:17:32,391] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:17:32,399] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:17:32,417] {logging_mixin.py:104} INFO - [2021-08-19 03:17:32,417] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:17:32,428] {logging_mixin.py:104} INFO - [2021-08-19 03:17:32,428] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:15:00+00:00
[2021-08-19 03:17:32,439] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.053 seconds
[2021-08-19 03:18:02,949] {scheduler_job.py:181} INFO - Started process (PID=11408) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:18:02,950] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:18:02,951] {logging_mixin.py:104} INFO - [2021-08-19 03:18:02,951] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:18:02,958] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:18:02,977] {logging_mixin.py:104} INFO - [2021-08-19 03:18:02,976] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:18:02,987] {logging_mixin.py:104} INFO - [2021-08-19 03:18:02,987] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:15:00+00:00
[2021-08-19 03:18:02,998] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.053 seconds
[2021-08-19 03:18:33,716] {scheduler_job.py:181} INFO - Started process (PID=11471) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:18:33,717] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:18:33,718] {logging_mixin.py:104} INFO - [2021-08-19 03:18:33,718] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:18:33,727] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:18:33,746] {logging_mixin.py:104} INFO - [2021-08-19 03:18:33,746] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:18:33,758] {logging_mixin.py:104} INFO - [2021-08-19 03:18:33,758] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:15:00+00:00
[2021-08-19 03:18:33,771] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.058 seconds
[2021-08-19 03:19:04,142] {scheduler_job.py:181} INFO - Started process (PID=11534) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:19:04,143] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:19:04,144] {logging_mixin.py:104} INFO - [2021-08-19 03:19:04,144] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:19:04,152] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:19:04,171] {logging_mixin.py:104} INFO - [2021-08-19 03:19:04,170] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:19:04,183] {logging_mixin.py:104} INFO - [2021-08-19 03:19:04,183] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:15:00+00:00
[2021-08-19 03:19:04,192] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.052 seconds
[2021-08-19 03:19:34,818] {scheduler_job.py:181} INFO - Started process (PID=11586) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:19:34,820] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:19:34,821] {logging_mixin.py:104} INFO - [2021-08-19 03:19:34,821] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:19:34,839] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:19:34,867] {logging_mixin.py:104} INFO - [2021-08-19 03:19:34,867] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:19:34,884] {logging_mixin.py:104} INFO - [2021-08-19 03:19:34,884] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:15:00+00:00
[2021-08-19 03:19:34,898] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.084 seconds
[2021-08-19 03:20:05,120] {scheduler_job.py:181} INFO - Started process (PID=11647) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:20:05,121] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:20:05,121] {logging_mixin.py:104} INFO - [2021-08-19 03:20:05,121] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:20:05,131] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:20:05,149] {logging_mixin.py:104} INFO - [2021-08-19 03:20:05,149] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:20:05,159] {logging_mixin.py:104} INFO - [2021-08-19 03:20:05,159] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:15:00+00:00
[2021-08-19 03:20:05,171] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.054 seconds
[2021-08-19 03:20:35,607] {scheduler_job.py:181} INFO - Started process (PID=11701) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:20:35,608] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:20:35,608] {logging_mixin.py:104} INFO - [2021-08-19 03:20:35,608] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:20:35,616] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:20:35,635] {logging_mixin.py:104} INFO - [2021-08-19 03:20:35,635] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:20:35,645] {logging_mixin.py:104} INFO - [2021-08-19 03:20:35,645] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:15:00+00:00
[2021-08-19 03:20:35,656] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.052 seconds
[2021-08-19 03:21:06,078] {scheduler_job.py:181} INFO - Started process (PID=11763) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:21:06,079] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:21:06,079] {logging_mixin.py:104} INFO - [2021-08-19 03:21:06,079] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:21:06,087] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:21:06,106] {logging_mixin.py:104} INFO - [2021-08-19 03:21:06,106] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:21:06,117] {logging_mixin.py:104} INFO - [2021-08-19 03:21:06,117] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:15:00+00:00
[2021-08-19 03:21:06,130] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.055 seconds
[2021-08-19 03:21:36,700] {scheduler_job.py:181} INFO - Started process (PID=11826) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:21:36,701] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:21:36,701] {logging_mixin.py:104} INFO - [2021-08-19 03:21:36,701] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:21:36,710] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:21:36,728] {logging_mixin.py:104} INFO - [2021-08-19 03:21:36,728] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:21:36,742] {logging_mixin.py:104} INFO - [2021-08-19 03:21:36,742] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:15:00+00:00
[2021-08-19 03:21:36,754] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.058 seconds
[2021-08-19 03:22:06,853] {scheduler_job.py:181} INFO - Started process (PID=11878) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:22:06,854] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:22:06,855] {logging_mixin.py:104} INFO - [2021-08-19 03:22:06,855] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:22:06,865] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:22:06,886] {logging_mixin.py:104} INFO - [2021-08-19 03:22:06,886] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:22:06,898] {logging_mixin.py:104} INFO - [2021-08-19 03:22:06,897] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:15:00+00:00
[2021-08-19 03:22:06,911] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.062 seconds
[2021-08-19 03:22:37,249] {scheduler_job.py:181} INFO - Started process (PID=11941) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:22:37,250] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:22:37,250] {logging_mixin.py:104} INFO - [2021-08-19 03:22:37,250] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:22:37,261] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:22:37,280] {logging_mixin.py:104} INFO - [2021-08-19 03:22:37,280] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:22:37,291] {logging_mixin.py:104} INFO - [2021-08-19 03:22:37,291] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:15:00+00:00
[2021-08-19 03:22:37,302] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.056 seconds
[2021-08-19 03:23:07,919] {scheduler_job.py:181} INFO - Started process (PID=12006) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:23:07,920] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:23:07,921] {logging_mixin.py:104} INFO - [2021-08-19 03:23:07,921] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:23:07,935] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:23:07,963] {logging_mixin.py:104} INFO - [2021-08-19 03:23:07,963] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:23:07,981] {logging_mixin.py:104} INFO - [2021-08-19 03:23:07,981] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:15:00+00:00
[2021-08-19 03:23:07,996] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.081 seconds
[2021-08-19 03:23:38,433] {scheduler_job.py:181} INFO - Started process (PID=12059) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:23:38,435] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:23:38,436] {logging_mixin.py:104} INFO - [2021-08-19 03:23:38,435] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:23:38,443] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:23:38,462] {logging_mixin.py:104} INFO - [2021-08-19 03:23:38,462] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:23:38,474] {logging_mixin.py:104} INFO - [2021-08-19 03:23:38,474] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:15:00+00:00
[2021-08-19 03:23:38,485] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.054 seconds
[2021-08-19 03:24:08,822] {scheduler_job.py:181} INFO - Started process (PID=12121) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:24:08,824] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:24:08,824] {logging_mixin.py:104} INFO - [2021-08-19 03:24:08,824] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:24:08,836] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:24:08,855] {logging_mixin.py:104} INFO - [2021-08-19 03:24:08,855] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:24:08,866] {logging_mixin.py:104} INFO - [2021-08-19 03:24:08,866] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:15:00+00:00
[2021-08-19 03:24:08,879] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.060 seconds
[2021-08-19 03:24:38,992] {scheduler_job.py:181} INFO - Started process (PID=12184) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:24:38,994] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:24:38,994] {logging_mixin.py:104} INFO - [2021-08-19 03:24:38,994] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:24:39,010] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:24:39,043] {logging_mixin.py:104} INFO - [2021-08-19 03:24:39,043] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:24:39,062] {logging_mixin.py:104} INFO - [2021-08-19 03:24:39,062] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:15:00+00:00
[2021-08-19 03:24:39,079] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.093 seconds
[2021-08-19 03:25:10,017] {scheduler_job.py:181} INFO - Started process (PID=12236) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:25:10,018] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:25:10,018] {logging_mixin.py:104} INFO - [2021-08-19 03:25:10,018] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:25:10,027] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:25:10,046] {logging_mixin.py:104} INFO - [2021-08-19 03:25:10,046] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:25:10,060] {logging_mixin.py:104} INFO - [2021-08-19 03:25:10,059] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:15:00+00:00
[2021-08-19 03:25:10,071] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.057 seconds
[2021-08-19 03:25:40,666] {scheduler_job.py:181} INFO - Started process (PID=12299) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:25:40,668] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:25:40,669] {logging_mixin.py:104} INFO - [2021-08-19 03:25:40,669] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:25:40,686] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:25:40,717] {logging_mixin.py:104} INFO - [2021-08-19 03:25:40,717] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:25:40,735] {logging_mixin.py:104} INFO - [2021-08-19 03:25:40,735] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:15:00+00:00
[2021-08-19 03:25:40,749] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.091 seconds
[2021-08-19 03:26:10,781] {scheduler_job.py:181} INFO - Started process (PID=12362) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:26:10,782] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:26:10,783] {logging_mixin.py:104} INFO - [2021-08-19 03:26:10,783] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:26:10,792] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:26:10,811] {logging_mixin.py:104} INFO - [2021-08-19 03:26:10,810] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:26:10,821] {logging_mixin.py:104} INFO - [2021-08-19 03:26:10,821] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:15:00+00:00
[2021-08-19 03:26:10,831] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.052 seconds
[2021-08-19 03:26:41,599] {scheduler_job.py:181} INFO - Started process (PID=12423) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:26:41,600] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:26:41,600] {logging_mixin.py:104} INFO - [2021-08-19 03:26:41,600] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:26:41,610] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:26:41,630] {logging_mixin.py:104} INFO - [2021-08-19 03:26:41,630] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:26:41,642] {logging_mixin.py:104} INFO - [2021-08-19 03:26:41,642] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:15:00+00:00
[2021-08-19 03:26:41,670] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.073 seconds
[2021-08-19 03:27:12,587] {scheduler_job.py:181} INFO - Started process (PID=12477) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:27:12,587] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:27:12,588] {logging_mixin.py:104} INFO - [2021-08-19 03:27:12,588] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:27:12,596] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:27:12,615] {logging_mixin.py:104} INFO - [2021-08-19 03:27:12,615] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:27:12,626] {logging_mixin.py:104} INFO - [2021-08-19 03:27:12,626] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:15:00+00:00
[2021-08-19 03:27:12,637] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.054 seconds
[2021-08-19 03:27:43,151] {scheduler_job.py:181} INFO - Started process (PID=12540) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:27:43,152] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:27:43,153] {logging_mixin.py:104} INFO - [2021-08-19 03:27:43,153] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:27:43,162] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:27:43,181] {logging_mixin.py:104} INFO - [2021-08-19 03:27:43,181] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:27:43,194] {logging_mixin.py:104} INFO - [2021-08-19 03:27:43,194] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:15:00+00:00
[2021-08-19 03:27:43,204] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.056 seconds
[2021-08-19 03:28:13,722] {scheduler_job.py:181} INFO - Started process (PID=12603) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:28:13,724] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:28:13,726] {logging_mixin.py:104} INFO - [2021-08-19 03:28:13,725] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:28:13,738] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:28:13,762] {logging_mixin.py:104} INFO - [2021-08-19 03:28:13,762] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:28:13,776] {logging_mixin.py:104} INFO - [2021-08-19 03:28:13,776] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:15:00+00:00
[2021-08-19 03:28:13,789] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.070 seconds
[2021-08-19 03:28:44,527] {scheduler_job.py:181} INFO - Started process (PID=12656) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:28:44,528] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:28:44,529] {logging_mixin.py:104} INFO - [2021-08-19 03:28:44,528] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:28:44,537] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:28:44,555] {logging_mixin.py:104} INFO - [2021-08-19 03:28:44,555] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:28:44,565] {logging_mixin.py:104} INFO - [2021-08-19 03:28:44,565] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:15:00+00:00
[2021-08-19 03:28:44,576] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.051 seconds
[2021-08-19 03:29:15,225] {scheduler_job.py:181} INFO - Started process (PID=12718) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:29:15,228] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:29:15,229] {logging_mixin.py:104} INFO - [2021-08-19 03:29:15,229] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:29:15,245] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:29:15,279] {logging_mixin.py:104} INFO - [2021-08-19 03:29:15,279] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:29:15,313] {logging_mixin.py:104} INFO - [2021-08-19 03:29:15,313] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:15:00+00:00
[2021-08-19 03:29:15,335] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.114 seconds
[2021-08-19 03:29:45,625] {scheduler_job.py:181} INFO - Started process (PID=12782) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:29:45,626] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:29:45,627] {logging_mixin.py:104} INFO - [2021-08-19 03:29:45,626] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:29:45,634] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:29:45,652] {logging_mixin.py:104} INFO - [2021-08-19 03:29:45,652] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:29:45,663] {logging_mixin.py:104} INFO - [2021-08-19 03:29:45,663] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:15:00+00:00
[2021-08-19 03:29:45,674] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.052 seconds
[2021-08-19 03:30:16,058] {scheduler_job.py:181} INFO - Started process (PID=12836) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:30:16,059] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:30:16,059] {logging_mixin.py:104} INFO - [2021-08-19 03:30:16,059] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:30:16,068] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:30:16,085] {logging_mixin.py:104} INFO - [2021-08-19 03:30:16,085] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:30:16,097] {logging_mixin.py:104} INFO - [2021-08-19 03:30:16,097] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 03:30:16,107] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.052 seconds
[2021-08-19 03:30:46,687] {scheduler_job.py:181} INFO - Started process (PID=12898) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:30:46,688] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:30:46,688] {logging_mixin.py:104} INFO - [2021-08-19 03:30:46,688] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:30:46,697] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:30:46,716] {logging_mixin.py:104} INFO - [2021-08-19 03:30:46,716] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:30:46,726] {logging_mixin.py:104} INFO - [2021-08-19 03:30:46,726] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 03:30:46,735] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.051 seconds
[2021-08-19 03:31:17,226] {scheduler_job.py:181} INFO - Started process (PID=12962) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:31:17,227] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:31:17,228] {logging_mixin.py:104} INFO - [2021-08-19 03:31:17,227] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:31:17,236] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:31:17,256] {logging_mixin.py:104} INFO - [2021-08-19 03:31:17,256] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:31:17,267] {logging_mixin.py:104} INFO - [2021-08-19 03:31:17,267] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 03:31:17,278] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.055 seconds
[2021-08-19 03:31:48,055] {scheduler_job.py:181} INFO - Started process (PID=13015) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:31:48,056] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:31:48,056] {logging_mixin.py:104} INFO - [2021-08-19 03:31:48,056] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:31:48,066] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:31:48,087] {logging_mixin.py:104} INFO - [2021-08-19 03:31:48,087] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:31:48,100] {logging_mixin.py:104} INFO - [2021-08-19 03:31:48,100] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 03:31:48,111] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.060 seconds
[2021-08-19 03:32:18,587] {scheduler_job.py:181} INFO - Started process (PID=13078) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:32:18,588] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:32:18,589] {logging_mixin.py:104} INFO - [2021-08-19 03:32:18,589] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:32:18,598] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:32:18,617] {logging_mixin.py:104} INFO - [2021-08-19 03:32:18,617] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:32:18,627] {logging_mixin.py:104} INFO - [2021-08-19 03:32:18,627] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 03:32:18,637] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.052 seconds
[2021-08-19 03:32:49,184] {scheduler_job.py:181} INFO - Started process (PID=13140) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:32:49,185] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:32:49,186] {logging_mixin.py:104} INFO - [2021-08-19 03:32:49,186] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:32:49,196] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:32:49,216] {logging_mixin.py:104} INFO - [2021-08-19 03:32:49,216] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:32:49,226] {logging_mixin.py:104} INFO - [2021-08-19 03:32:49,226] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 03:32:49,237] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.058 seconds
[2021-08-19 03:33:19,851] {scheduler_job.py:181} INFO - Started process (PID=13203) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:33:19,852] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:33:19,852] {logging_mixin.py:104} INFO - [2021-08-19 03:33:19,852] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:33:19,861] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:33:19,881] {logging_mixin.py:104} INFO - [2021-08-19 03:33:19,881] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:33:19,893] {logging_mixin.py:104} INFO - [2021-08-19 03:33:19,893] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 03:33:19,905] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.057 seconds
[2021-08-19 03:33:50,415] {scheduler_job.py:181} INFO - Started process (PID=13255) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:33:50,416] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:33:50,417] {logging_mixin.py:104} INFO - [2021-08-19 03:33:50,416] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:33:50,426] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:33:50,447] {logging_mixin.py:104} INFO - [2021-08-19 03:33:50,447] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:33:50,459] {logging_mixin.py:104} INFO - [2021-08-19 03:33:50,459] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 03:33:50,472] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.060 seconds
[2021-08-19 03:34:21,138] {scheduler_job.py:181} INFO - Started process (PID=13318) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:34:21,140] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:34:21,140] {logging_mixin.py:104} INFO - [2021-08-19 03:34:21,140] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:34:21,148] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:34:21,168] {logging_mixin.py:104} INFO - [2021-08-19 03:34:21,168] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:34:21,178] {logging_mixin.py:104} INFO - [2021-08-19 03:34:21,178] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 03:34:21,189] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.054 seconds
[2021-08-19 03:34:52,091] {scheduler_job.py:181} INFO - Started process (PID=13380) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:34:52,092] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:34:52,092] {logging_mixin.py:104} INFO - [2021-08-19 03:34:52,092] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:34:52,101] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:34:52,121] {logging_mixin.py:104} INFO - [2021-08-19 03:34:52,121] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:34:52,134] {logging_mixin.py:104} INFO - [2021-08-19 03:34:52,134] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 03:34:52,146] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.058 seconds
[2021-08-19 03:35:22,736] {scheduler_job.py:181} INFO - Started process (PID=13433) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:35:22,737] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:35:22,738] {logging_mixin.py:104} INFO - [2021-08-19 03:35:22,738] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:35:22,746] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:35:22,766] {logging_mixin.py:104} INFO - [2021-08-19 03:35:22,766] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:35:22,777] {logging_mixin.py:104} INFO - [2021-08-19 03:35:22,776] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 03:35:22,787] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.054 seconds
[2021-08-19 03:35:53,313] {scheduler_job.py:181} INFO - Started process (PID=13496) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:35:53,314] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:35:53,314] {logging_mixin.py:104} INFO - [2021-08-19 03:35:53,314] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:35:53,323] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:35:53,342] {logging_mixin.py:104} INFO - [2021-08-19 03:35:53,342] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:35:53,353] {logging_mixin.py:104} INFO - [2021-08-19 03:35:53,353] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 03:35:53,364] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.054 seconds
[2021-08-19 03:36:23,881] {scheduler_job.py:181} INFO - Started process (PID=13559) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:36:23,882] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:36:23,883] {logging_mixin.py:104} INFO - [2021-08-19 03:36:23,882] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:36:23,891] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:36:23,910] {logging_mixin.py:104} INFO - [2021-08-19 03:36:23,910] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:36:23,921] {logging_mixin.py:104} INFO - [2021-08-19 03:36:23,920] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 03:36:23,931] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.053 seconds
[2021-08-19 03:36:54,231] {scheduler_job.py:181} INFO - Started process (PID=13617) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:36:54,232] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:36:54,233] {logging_mixin.py:104} INFO - [2021-08-19 03:36:54,233] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:36:54,242] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:36:54,261] {logging_mixin.py:104} INFO - [2021-08-19 03:36:54,260] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:36:54,274] {logging_mixin.py:104} INFO - [2021-08-19 03:36:54,273] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 03:36:54,284] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.056 seconds
[2021-08-19 03:37:24,732] {scheduler_job.py:181} INFO - Started process (PID=13674) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:37:24,734] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:37:24,734] {logging_mixin.py:104} INFO - [2021-08-19 03:37:24,734] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:37:24,746] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:37:24,768] {logging_mixin.py:104} INFO - [2021-08-19 03:37:24,768] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:37:24,783] {logging_mixin.py:104} INFO - [2021-08-19 03:37:24,782] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 03:37:24,801] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.072 seconds
[2021-08-19 03:37:55,476] {scheduler_job.py:181} INFO - Started process (PID=13736) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:37:55,477] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:37:55,478] {logging_mixin.py:104} INFO - [2021-08-19 03:37:55,478] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:37:55,486] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:37:55,505] {logging_mixin.py:104} INFO - [2021-08-19 03:37:55,505] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:37:55,519] {logging_mixin.py:104} INFO - [2021-08-19 03:37:55,519] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 03:37:55,531] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.058 seconds
[2021-08-19 03:38:25,987] {scheduler_job.py:181} INFO - Started process (PID=13800) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:38:25,989] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:38:25,989] {logging_mixin.py:104} INFO - [2021-08-19 03:38:25,989] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:38:26,003] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:38:26,032] {logging_mixin.py:104} INFO - [2021-08-19 03:38:26,032] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:38:26,055] {logging_mixin.py:104} INFO - [2021-08-19 03:38:26,055] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 03:38:26,073] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.091 seconds
[2021-08-19 03:38:56,605] {scheduler_job.py:181} INFO - Started process (PID=13854) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:38:56,606] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:38:56,607] {logging_mixin.py:104} INFO - [2021-08-19 03:38:56,607] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:38:56,616] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:38:56,635] {logging_mixin.py:104} INFO - [2021-08-19 03:38:56,635] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:38:56,646] {logging_mixin.py:104} INFO - [2021-08-19 03:38:56,646] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 03:38:56,658] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.055 seconds
[2021-08-19 03:39:27,306] {scheduler_job.py:181} INFO - Started process (PID=13918) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:39:27,308] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:39:27,308] {logging_mixin.py:104} INFO - [2021-08-19 03:39:27,308] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:39:27,317] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:39:27,336] {logging_mixin.py:104} INFO - [2021-08-19 03:39:27,336] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:39:27,349] {logging_mixin.py:104} INFO - [2021-08-19 03:39:27,349] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 03:39:27,360] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.056 seconds
[2021-08-19 03:39:57,535] {scheduler_job.py:181} INFO - Started process (PID=13972) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 03:39:57,536] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 03:39:57,537] {logging_mixin.py:104} INFO - [2021-08-19 03:39:57,537] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:39:57,545] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 03:39:57,564] {logging_mixin.py:104} INFO - [2021-08-19 03:39:57,564] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 03:39:57,575] {logging_mixin.py:104} INFO - [2021-08-19 03:39:57,575] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 03:39:57,587] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.054 seconds
[2021-08-19 14:40:20,278] {scheduler_job.py:181} INFO - Started process (PID=14024) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 14:40:20,309] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 14:40:20,310] {logging_mixin.py:104} INFO - [2021-08-19 14:40:20,309] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 14:40:20,379] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 14:40:20,490] {logging_mixin.py:104} INFO - [2021-08-19 14:40:20,490] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 14:40:20,564] {logging_mixin.py:104} INFO - [2021-08-19 14:40:20,564] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 14:40:20,641] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.367 seconds
[2021-08-19 16:19:08,321] {scheduler_job.py:181} INFO - Started process (PID=14041) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:19:08,351] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:19:08,352] {logging_mixin.py:104} INFO - [2021-08-19 16:19:08,352] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:19:08,414] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:19:08,484] {logging_mixin.py:104} INFO - [2021-08-19 16:19:08,484] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:19:08,512] {logging_mixin.py:104} INFO - [2021-08-19 16:19:08,512] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 16:19:08,538] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.247 seconds
[2021-08-19 16:19:38,846] {scheduler_job.py:181} INFO - Started process (PID=14095) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:19:38,847] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:19:38,848] {logging_mixin.py:104} INFO - [2021-08-19 16:19:38,848] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:19:38,856] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:19:38,876] {logging_mixin.py:104} INFO - [2021-08-19 16:19:38,876] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:19:38,888] {logging_mixin.py:104} INFO - [2021-08-19 16:19:38,887] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 16:19:38,899] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.055 seconds
[2021-08-19 16:20:09,309] {scheduler_job.py:181} INFO - Started process (PID=14160) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:20:09,310] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:20:09,311] {logging_mixin.py:104} INFO - [2021-08-19 16:20:09,311] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:20:09,322] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:20:09,341] {logging_mixin.py:104} INFO - [2021-08-19 16:20:09,341] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:20:09,355] {logging_mixin.py:104} INFO - [2021-08-19 16:20:09,355] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 16:20:09,367] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.061 seconds
[2021-08-19 16:20:39,891] {scheduler_job.py:181} INFO - Started process (PID=14225) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:20:39,892] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:20:39,893] {logging_mixin.py:104} INFO - [2021-08-19 16:20:39,892] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:20:39,903] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:20:39,924] {logging_mixin.py:104} INFO - [2021-08-19 16:20:39,924] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:20:39,937] {logging_mixin.py:104} INFO - [2021-08-19 16:20:39,937] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 16:20:39,951] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.062 seconds
[2021-08-19 16:21:10,339] {scheduler_job.py:181} INFO - Started process (PID=14277) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:21:10,341] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:21:10,342] {logging_mixin.py:104} INFO - [2021-08-19 16:21:10,342] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:21:10,355] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:21:10,394] {logging_mixin.py:104} INFO - [2021-08-19 16:21:10,394] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:21:10,422] {logging_mixin.py:104} INFO - [2021-08-19 16:21:10,422] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 16:21:10,490] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.154 seconds
[2021-08-19 16:21:41,213] {scheduler_job.py:181} INFO - Started process (PID=14340) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:21:41,214] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:21:41,214] {logging_mixin.py:104} INFO - [2021-08-19 16:21:41,214] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:21:41,223] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:21:41,243] {logging_mixin.py:104} INFO - [2021-08-19 16:21:41,243] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:21:41,255] {logging_mixin.py:104} INFO - [2021-08-19 16:21:41,254] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 16:21:41,268] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.058 seconds
[2021-08-19 16:22:11,721] {scheduler_job.py:181} INFO - Started process (PID=14403) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:22:11,722] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:22:11,723] {logging_mixin.py:104} INFO - [2021-08-19 16:22:11,723] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:22:11,731] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:22:11,750] {logging_mixin.py:104} INFO - [2021-08-19 16:22:11,750] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:22:11,765] {logging_mixin.py:104} INFO - [2021-08-19 16:22:11,765] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 16:22:11,777] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.061 seconds
[2021-08-19 16:22:42,217] {scheduler_job.py:181} INFO - Started process (PID=14466) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:22:42,219] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:22:42,219] {logging_mixin.py:104} INFO - [2021-08-19 16:22:42,219] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:22:42,230] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:22:42,251] {logging_mixin.py:104} INFO - [2021-08-19 16:22:42,251] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:22:42,268] {logging_mixin.py:104} INFO - [2021-08-19 16:22:42,268] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 16:22:42,278] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.064 seconds
[2021-08-19 16:23:12,647] {scheduler_job.py:181} INFO - Started process (PID=14518) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:23:12,649] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:23:12,650] {logging_mixin.py:104} INFO - [2021-08-19 16:23:12,649] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:23:12,660] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:23:12,686] {logging_mixin.py:104} INFO - [2021-08-19 16:23:12,686] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:23:12,710] {logging_mixin.py:104} INFO - [2021-08-19 16:23:12,709] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 16:23:12,743] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.101 seconds
[2021-08-19 16:23:43,428] {scheduler_job.py:181} INFO - Started process (PID=14581) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:23:43,429] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:23:43,430] {logging_mixin.py:104} INFO - [2021-08-19 16:23:43,430] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:23:43,438] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:23:43,458] {logging_mixin.py:104} INFO - [2021-08-19 16:23:43,458] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:23:43,470] {logging_mixin.py:104} INFO - [2021-08-19 16:23:43,470] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 16:23:43,481] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.055 seconds
[2021-08-19 16:24:14,065] {scheduler_job.py:181} INFO - Started process (PID=14646) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:24:14,067] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:24:14,068] {logging_mixin.py:104} INFO - [2021-08-19 16:24:14,068] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:24:14,083] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:24:14,115] {logging_mixin.py:104} INFO - [2021-08-19 16:24:14,115] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:24:14,132] {logging_mixin.py:104} INFO - [2021-08-19 16:24:14,132] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 16:24:14,148] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.086 seconds
[2021-08-19 16:24:44,648] {scheduler_job.py:181} INFO - Started process (PID=14699) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:24:44,649] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:24:44,650] {logging_mixin.py:104} INFO - [2021-08-19 16:24:44,650] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:24:44,661] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:24:44,681] {logging_mixin.py:104} INFO - [2021-08-19 16:24:44,681] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:24:44,694] {logging_mixin.py:104} INFO - [2021-08-19 16:24:44,694] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 16:24:44,705] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.060 seconds
[2021-08-19 16:25:15,237] {scheduler_job.py:181} INFO - Started process (PID=14764) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:25:15,239] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:25:15,240] {logging_mixin.py:104} INFO - [2021-08-19 16:25:15,239] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:25:15,252] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:25:15,273] {logging_mixin.py:104} INFO - [2021-08-19 16:25:15,273] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:25:15,286] {logging_mixin.py:104} INFO - [2021-08-19 16:25:15,286] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 16:25:15,297] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.064 seconds
[2021-08-19 16:25:45,692] {scheduler_job.py:181} INFO - Started process (PID=14828) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:25:45,693] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:25:45,694] {logging_mixin.py:104} INFO - [2021-08-19 16:25:45,694] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:25:45,706] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:25:45,729] {logging_mixin.py:104} INFO - [2021-08-19 16:25:45,729] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:25:45,741] {logging_mixin.py:104} INFO - [2021-08-19 16:25:45,741] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 16:25:45,752] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.064 seconds
[2021-08-19 16:26:16,106] {scheduler_job.py:181} INFO - Started process (PID=14882) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:26:16,107] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:26:16,107] {logging_mixin.py:104} INFO - [2021-08-19 16:26:16,107] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:26:16,117] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:26:16,139] {logging_mixin.py:104} INFO - [2021-08-19 16:26:16,139] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:26:16,150] {logging_mixin.py:104} INFO - [2021-08-19 16:26:16,150] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 16:26:16,164] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.061 seconds
[2021-08-19 16:26:46,788] {scheduler_job.py:181} INFO - Started process (PID=14945) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:26:46,790] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:26:46,791] {logging_mixin.py:104} INFO - [2021-08-19 16:26:46,790] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:26:46,806] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:26:46,858] {logging_mixin.py:104} INFO - [2021-08-19 16:26:46,858] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:26:46,877] {logging_mixin.py:104} INFO - [2021-08-19 16:26:46,877] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 16:26:46,905] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.120 seconds
[2021-08-19 16:27:17,633] {scheduler_job.py:181} INFO - Started process (PID=15008) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:27:17,634] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:27:17,635] {logging_mixin.py:104} INFO - [2021-08-19 16:27:17,635] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:27:17,647] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:27:17,671] {logging_mixin.py:104} INFO - [2021-08-19 16:27:17,671] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:27:17,683] {logging_mixin.py:104} INFO - [2021-08-19 16:27:17,683] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 16:27:17,693] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.064 seconds
[2021-08-19 16:27:48,369] {scheduler_job.py:181} INFO - Started process (PID=15061) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:27:48,370] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:27:48,371] {logging_mixin.py:104} INFO - [2021-08-19 16:27:48,371] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:27:48,384] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:27:48,407] {logging_mixin.py:104} INFO - [2021-08-19 16:27:48,407] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:27:48,421] {logging_mixin.py:104} INFO - [2021-08-19 16:27:48,421] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 16:27:48,436] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.070 seconds
[2021-08-19 16:28:18,829] {scheduler_job.py:181} INFO - Started process (PID=15123) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:28:18,830] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:28:18,831] {logging_mixin.py:104} INFO - [2021-08-19 16:28:18,831] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:28:18,838] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:28:18,858] {logging_mixin.py:104} INFO - [2021-08-19 16:28:18,857] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:28:18,869] {logging_mixin.py:104} INFO - [2021-08-19 16:28:18,868] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 16:28:18,879] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.054 seconds
[2021-08-19 16:28:49,335] {scheduler_job.py:181} INFO - Started process (PID=15186) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:28:49,337] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:28:49,337] {logging_mixin.py:104} INFO - [2021-08-19 16:28:49,337] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:28:49,345] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:28:49,364] {logging_mixin.py:104} INFO - [2021-08-19 16:28:49,364] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:28:49,377] {logging_mixin.py:104} INFO - [2021-08-19 16:28:49,377] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 16:28:49,389] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.057 seconds
[2021-08-19 16:29:19,695] {scheduler_job.py:181} INFO - Started process (PID=15240) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:29:19,697] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:29:19,698] {logging_mixin.py:104} INFO - [2021-08-19 16:29:19,698] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:29:19,705] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:29:19,725] {logging_mixin.py:104} INFO - [2021-08-19 16:29:19,724] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:29:19,738] {logging_mixin.py:104} INFO - [2021-08-19 16:29:19,737] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 16:29:19,750] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.059 seconds
[2021-08-19 16:29:50,206] {scheduler_job.py:181} INFO - Started process (PID=15304) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:29:50,207] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:29:50,208] {logging_mixin.py:104} INFO - [2021-08-19 16:29:50,207] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:29:50,218] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:29:50,237] {logging_mixin.py:104} INFO - [2021-08-19 16:29:50,237] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:29:50,250] {logging_mixin.py:104} INFO - [2021-08-19 16:29:50,250] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 16:29:50,262] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.060 seconds
[2021-08-19 16:30:20,560] {scheduler_job.py:181} INFO - Started process (PID=15367) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:30:20,561] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:30:20,562] {logging_mixin.py:104} INFO - [2021-08-19 16:30:20,562] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:30:20,574] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:30:20,595] {logging_mixin.py:104} INFO - [2021-08-19 16:30:20,595] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:30:20,609] {logging_mixin.py:104} INFO - [2021-08-19 16:30:20,608] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 16:30:20,619] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.062 seconds
[2021-08-19 16:30:50,895] {scheduler_job.py:181} INFO - Started process (PID=15421) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:30:50,896] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:30:50,897] {logging_mixin.py:104} INFO - [2021-08-19 16:30:50,897] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:30:50,907] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:30:50,930] {logging_mixin.py:104} INFO - [2021-08-19 16:30:50,929] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:30:50,941] {logging_mixin.py:104} INFO - [2021-08-19 16:30:50,941] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 16:30:50,954] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.063 seconds
[2021-08-19 16:31:21,274] {scheduler_job.py:181} INFO - Started process (PID=15486) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:31:21,275] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:31:21,276] {logging_mixin.py:104} INFO - [2021-08-19 16:31:21,276] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:31:21,286] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:31:21,306] {logging_mixin.py:104} INFO - [2021-08-19 16:31:21,306] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:31:21,319] {logging_mixin.py:104} INFO - [2021-08-19 16:31:21,319] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 16:31:21,328] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.058 seconds
[2021-08-19 16:31:51,727] {scheduler_job.py:181} INFO - Started process (PID=15549) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:31:51,728] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:31:51,730] {logging_mixin.py:104} INFO - [2021-08-19 16:31:51,729] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:31:51,765] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:31:51,804] {logging_mixin.py:104} INFO - [2021-08-19 16:31:51,803] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:31:51,824] {logging_mixin.py:104} INFO - [2021-08-19 16:31:51,824] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 16:31:51,844] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.130 seconds
[2021-08-19 16:35:15,108] {scheduler_job.py:181} INFO - Started process (PID=15592) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:35:15,117] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:35:15,117] {logging_mixin.py:104} INFO - [2021-08-19 16:35:15,117] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:35:15,172] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:35:15,211] {logging_mixin.py:104} INFO - [2021-08-19 16:35:15,211] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:35:15,243] {logging_mixin.py:104} INFO - [2021-08-19 16:35:15,243] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 16:35:15,284] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.201 seconds
[2021-08-19 16:35:45,681] {scheduler_job.py:181} INFO - Started process (PID=15660) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:35:45,682] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:35:45,683] {logging_mixin.py:104} INFO - [2021-08-19 16:35:45,683] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:35:45,695] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:35:45,716] {logging_mixin.py:104} INFO - [2021-08-19 16:35:45,715] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:35:45,728] {logging_mixin.py:104} INFO - [2021-08-19 16:35:45,728] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 16:35:45,738] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.060 seconds
[2021-08-19 16:36:16,173] {scheduler_job.py:181} INFO - Started process (PID=15722) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:36:16,174] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:36:16,175] {logging_mixin.py:104} INFO - [2021-08-19 16:36:16,175] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:36:16,184] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:36:16,203] {logging_mixin.py:104} INFO - [2021-08-19 16:36:16,203] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:36:16,214] {logging_mixin.py:104} INFO - [2021-08-19 16:36:16,214] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 16:36:16,224] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.054 seconds
[2021-08-19 16:36:46,605] {scheduler_job.py:181} INFO - Started process (PID=15776) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:36:46,606] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:36:46,607] {logging_mixin.py:104} INFO - [2021-08-19 16:36:46,607] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:36:46,619] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:36:46,639] {logging_mixin.py:104} INFO - [2021-08-19 16:36:46,639] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:36:46,652] {logging_mixin.py:104} INFO - [2021-08-19 16:36:46,652] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 16:36:46,662] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.060 seconds
[2021-08-19 16:37:17,036] {scheduler_job.py:181} INFO - Started process (PID=15839) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:37:17,037] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:37:17,038] {logging_mixin.py:104} INFO - [2021-08-19 16:37:17,038] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:37:17,046] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:37:17,064] {logging_mixin.py:104} INFO - [2021-08-19 16:37:17,064] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:37:17,077] {logging_mixin.py:104} INFO - [2021-08-19 16:37:17,077] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 16:37:17,090] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.058 seconds
[2021-08-19 16:37:47,517] {scheduler_job.py:181} INFO - Started process (PID=15902) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:37:47,518] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:37:47,519] {logging_mixin.py:104} INFO - [2021-08-19 16:37:47,519] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:37:47,530] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:37:47,550] {logging_mixin.py:104} INFO - [2021-08-19 16:37:47,550] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:37:47,561] {logging_mixin.py:104} INFO - [2021-08-19 16:37:47,561] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 16:37:47,573] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.059 seconds
[2021-08-19 16:38:17,940] {scheduler_job.py:181} INFO - Started process (PID=15965) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:38:17,941] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:38:17,942] {logging_mixin.py:104} INFO - [2021-08-19 16:38:17,942] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:38:17,954] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:38:17,974] {logging_mixin.py:104} INFO - [2021-08-19 16:38:17,974] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:38:17,986] {logging_mixin.py:104} INFO - [2021-08-19 16:38:17,986] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 16:38:17,998] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.061 seconds
[2021-08-19 16:38:48,488] {scheduler_job.py:181} INFO - Started process (PID=16017) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:38:48,489] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:38:48,490] {logging_mixin.py:104} INFO - [2021-08-19 16:38:48,489] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:38:48,503] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:38:48,525] {logging_mixin.py:104} INFO - [2021-08-19 16:38:48,525] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:38:48,540] {logging_mixin.py:104} INFO - [2021-08-19 16:38:48,540] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T03:30:00+00:00
[2021-08-19 16:38:48,554] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.069 seconds
[2021-08-19 16:39:19,142] {scheduler_job.py:181} INFO - Started process (PID=16082) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:39:19,143] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:39:19,144] {logging_mixin.py:104} INFO - [2021-08-19 16:39:19,143] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:39:19,152] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:39:19,171] {logging_mixin.py:104} INFO - [2021-08-19 16:39:19,171] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:39:19,182] {logging_mixin.py:104} INFO - [2021-08-19 16:39:19,182] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T07:30:00+00:00
[2021-08-19 16:39:19,194] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.055 seconds
[2021-08-19 16:39:49,577] {scheduler_job.py:181} INFO - Started process (PID=16146) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:39:49,578] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:39:49,579] {logging_mixin.py:104} INFO - [2021-08-19 16:39:49,579] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:39:49,590] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:39:49,610] {logging_mixin.py:104} INFO - [2021-08-19 16:39:49,610] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:39:49,622] {logging_mixin.py:104} INFO - [2021-08-19 16:39:49,622] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T07:30:00+00:00
[2021-08-19 16:39:49,632] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.058 seconds
[2021-08-19 16:40:20,124] {scheduler_job.py:181} INFO - Started process (PID=16198) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:40:20,126] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:40:20,127] {logging_mixin.py:104} INFO - [2021-08-19 16:40:20,126] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:40:20,140] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:40:20,168] {logging_mixin.py:104} INFO - [2021-08-19 16:40:20,167] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:40:20,184] {logging_mixin.py:104} INFO - [2021-08-19 16:40:20,184] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T07:30:00+00:00
[2021-08-19 16:40:20,198] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.080 seconds
[2021-08-19 16:40:50,627] {scheduler_job.py:181} INFO - Started process (PID=16262) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:40:50,628] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:40:50,628] {logging_mixin.py:104} INFO - [2021-08-19 16:40:50,628] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:40:50,641] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:40:50,659] {logging_mixin.py:104} INFO - [2021-08-19 16:40:50,659] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:40:50,671] {logging_mixin.py:104} INFO - [2021-08-19 16:40:50,671] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T07:30:00+00:00
[2021-08-19 16:40:50,680] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.057 seconds
[2021-08-19 16:41:21,054] {scheduler_job.py:181} INFO - Started process (PID=16324) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:41:21,055] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:41:21,056] {logging_mixin.py:104} INFO - [2021-08-19 16:41:21,055] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:41:21,064] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:41:21,083] {logging_mixin.py:104} INFO - [2021-08-19 16:41:21,083] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:41:21,095] {logging_mixin.py:104} INFO - [2021-08-19 16:41:21,095] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T07:30:00+00:00
[2021-08-19 16:41:21,104] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.054 seconds
[2021-08-19 16:41:51,487] {scheduler_job.py:181} INFO - Started process (PID=16376) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:41:51,488] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:41:51,488] {logging_mixin.py:104} INFO - [2021-08-19 16:41:51,488] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:41:51,497] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:41:51,521] {logging_mixin.py:104} INFO - [2021-08-19 16:41:51,520] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:41:51,532] {logging_mixin.py:104} INFO - [2021-08-19 16:41:51,532] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T07:30:00+00:00
[2021-08-19 16:41:51,543] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.059 seconds
[2021-08-19 16:42:21,942] {scheduler_job.py:181} INFO - Started process (PID=16440) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:42:21,943] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:42:21,944] {logging_mixin.py:104} INFO - [2021-08-19 16:42:21,944] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:42:21,951] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:42:21,974] {logging_mixin.py:104} INFO - [2021-08-19 16:42:21,974] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:42:21,992] {logging_mixin.py:104} INFO - [2021-08-19 16:42:21,992] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T07:30:00+00:00
[2021-08-19 16:42:22,004] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.065 seconds
[2021-08-19 16:42:52,587] {scheduler_job.py:181} INFO - Started process (PID=16503) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:42:52,588] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:42:52,589] {logging_mixin.py:104} INFO - [2021-08-19 16:42:52,589] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:42:52,600] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:42:52,622] {logging_mixin.py:104} INFO - [2021-08-19 16:42:52,621] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:42:52,634] {logging_mixin.py:104} INFO - [2021-08-19 16:42:52,634] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T07:30:00+00:00
[2021-08-19 16:42:52,644] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.059 seconds
[2021-08-19 16:43:23,031] {scheduler_job.py:181} INFO - Started process (PID=16556) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:43:23,032] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:43:23,033] {logging_mixin.py:104} INFO - [2021-08-19 16:43:23,033] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:43:23,041] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:43:23,061] {logging_mixin.py:104} INFO - [2021-08-19 16:43:23,060] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:43:23,073] {logging_mixin.py:104} INFO - [2021-08-19 16:43:23,073] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T07:30:00+00:00
[2021-08-19 16:43:23,086] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.058 seconds
[2021-08-19 16:43:53,563] {scheduler_job.py:181} INFO - Started process (PID=16618) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:43:53,564] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:43:53,564] {logging_mixin.py:104} INFO - [2021-08-19 16:43:53,564] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:43:53,572] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:43:53,591] {logging_mixin.py:104} INFO - [2021-08-19 16:43:53,591] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:43:53,603] {logging_mixin.py:104} INFO - [2021-08-19 16:43:53,603] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T07:30:00+00:00
[2021-08-19 16:43:53,614] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.054 seconds
[2021-08-19 16:44:24,010] {scheduler_job.py:181} INFO - Started process (PID=16710) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:44:24,011] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:44:24,012] {logging_mixin.py:104} INFO - [2021-08-19 16:44:24,012] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:44:24,022] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:44:24,045] {logging_mixin.py:104} INFO - [2021-08-19 16:44:24,045] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:44:24,056] {logging_mixin.py:104} INFO - [2021-08-19 16:44:24,056] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T07:30:00+00:00
[2021-08-19 16:44:24,069] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.062 seconds
[2021-08-19 16:44:54,083] {scheduler_job.py:181} INFO - Started process (PID=16764) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:44:54,084] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:44:54,085] {logging_mixin.py:104} INFO - [2021-08-19 16:44:54,085] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:44:54,093] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:44:54,112] {logging_mixin.py:104} INFO - [2021-08-19 16:44:54,112] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:44:54,125] {logging_mixin.py:104} INFO - [2021-08-19 16:44:54,125] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T11:30:00+00:00
[2021-08-19 16:44:54,137] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.056 seconds
[2021-08-19 16:45:24,682] {scheduler_job.py:181} INFO - Started process (PID=16826) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:45:24,683] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:45:24,684] {logging_mixin.py:104} INFO - [2021-08-19 16:45:24,684] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:45:24,695] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:45:24,715] {logging_mixin.py:104} INFO - [2021-08-19 16:45:24,714] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:45:24,725] {logging_mixin.py:104} INFO - [2021-08-19 16:45:24,725] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T11:30:00+00:00
[2021-08-19 16:45:24,738] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.060 seconds
[2021-08-19 16:45:55,156] {scheduler_job.py:181} INFO - Started process (PID=16891) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:45:55,157] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:45:55,158] {logging_mixin.py:104} INFO - [2021-08-19 16:45:55,158] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:45:55,168] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:45:55,186] {logging_mixin.py:104} INFO - [2021-08-19 16:45:55,186] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:45:55,197] {logging_mixin.py:104} INFO - [2021-08-19 16:45:55,197] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T11:30:00+00:00
[2021-08-19 16:45:55,208] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.056 seconds
[2021-08-19 16:46:25,568] {scheduler_job.py:181} INFO - Started process (PID=16954) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:46:25,570] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:46:25,570] {logging_mixin.py:104} INFO - [2021-08-19 16:46:25,570] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:46:25,580] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:46:25,599] {logging_mixin.py:104} INFO - [2021-08-19 16:46:25,599] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:46:25,612] {logging_mixin.py:104} INFO - [2021-08-19 16:46:25,612] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T11:30:00+00:00
[2021-08-19 16:46:25,624] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.059 seconds
[2021-08-19 16:46:56,048] {scheduler_job.py:181} INFO - Started process (PID=17006) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:46:56,049] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:46:56,050] {logging_mixin.py:104} INFO - [2021-08-19 16:46:56,050] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:46:56,061] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:46:56,082] {logging_mixin.py:104} INFO - [2021-08-19 16:46:56,082] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:46:56,094] {logging_mixin.py:104} INFO - [2021-08-19 16:46:56,094] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T11:30:00+00:00
[2021-08-19 16:46:56,106] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.061 seconds
[2021-08-19 16:47:26,705] {scheduler_job.py:181} INFO - Started process (PID=17068) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:47:26,707] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:47:26,707] {logging_mixin.py:104} INFO - [2021-08-19 16:47:26,707] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:47:26,716] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:47:26,740] {logging_mixin.py:104} INFO - [2021-08-19 16:47:26,740] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:47:26,754] {logging_mixin.py:104} INFO - [2021-08-19 16:47:26,754] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T11:30:00+00:00
[2021-08-19 16:47:26,765] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.063 seconds
[2021-08-19 16:47:57,145] {scheduler_job.py:181} INFO - Started process (PID=17131) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:47:57,146] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:47:57,147] {logging_mixin.py:104} INFO - [2021-08-19 16:47:57,147] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:47:57,157] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:47:57,177] {logging_mixin.py:104} INFO - [2021-08-19 16:47:57,177] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:47:57,193] {logging_mixin.py:104} INFO - [2021-08-19 16:47:57,193] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T11:30:00+00:00
[2021-08-19 16:47:57,204] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.061 seconds
[2021-08-19 16:48:27,573] {scheduler_job.py:181} INFO - Started process (PID=17185) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:48:27,574] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:48:27,575] {logging_mixin.py:104} INFO - [2021-08-19 16:48:27,575] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:48:27,584] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:48:27,604] {logging_mixin.py:104} INFO - [2021-08-19 16:48:27,604] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:48:27,616] {logging_mixin.py:104} INFO - [2021-08-19 16:48:27,616] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T11:30:00+00:00
[2021-08-19 16:48:27,627] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.057 seconds
[2021-08-19 16:48:58,057] {scheduler_job.py:181} INFO - Started process (PID=17247) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:48:58,058] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:48:58,058] {logging_mixin.py:104} INFO - [2021-08-19 16:48:58,058] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:48:58,066] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:48:58,087] {logging_mixin.py:104} INFO - [2021-08-19 16:48:58,086] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:48:58,099] {logging_mixin.py:104} INFO - [2021-08-19 16:48:58,099] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T11:30:00+00:00
[2021-08-19 16:48:58,111] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.057 seconds
[2021-08-19 16:49:28,494] {scheduler_job.py:181} INFO - Started process (PID=17324) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:49:28,495] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:49:28,496] {logging_mixin.py:104} INFO - [2021-08-19 16:49:28,496] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:49:28,505] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:49:28,524] {logging_mixin.py:104} INFO - [2021-08-19 16:49:28,524] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:49:28,538] {logging_mixin.py:104} INFO - [2021-08-19 16:49:28,537] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T11:30:00+00:00
[2021-08-19 16:49:28,549] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.058 seconds
[2021-08-19 16:49:59,174] {scheduler_job.py:181} INFO - Started process (PID=17383) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:49:59,175] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:49:59,175] {logging_mixin.py:104} INFO - [2021-08-19 16:49:59,175] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:49:59,185] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:49:59,208] {logging_mixin.py:104} INFO - [2021-08-19 16:49:59,208] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:49:59,221] {logging_mixin.py:104} INFO - [2021-08-19 16:49:59,221] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T15:30:00+00:00
[2021-08-19 16:49:59,234] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.064 seconds
[2021-08-19 16:50:29,594] {scheduler_job.py:181} INFO - Started process (PID=17446) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:50:29,596] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:50:29,596] {logging_mixin.py:104} INFO - [2021-08-19 16:50:29,596] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:50:29,608] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:50:29,627] {logging_mixin.py:104} INFO - [2021-08-19 16:50:29,627] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:50:29,639] {logging_mixin.py:104} INFO - [2021-08-19 16:50:29,639] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T15:30:00+00:00
[2021-08-19 16:50:29,651] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.060 seconds
[2021-08-19 16:51:00,104] {scheduler_job.py:181} INFO - Started process (PID=17511) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:51:00,105] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:51:00,106] {logging_mixin.py:104} INFO - [2021-08-19 16:51:00,106] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:51:00,117] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:51:00,138] {logging_mixin.py:104} INFO - [2021-08-19 16:51:00,138] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:51:00,150] {logging_mixin.py:104} INFO - [2021-08-19 16:51:00,150] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T15:30:00+00:00
[2021-08-19 16:51:00,162] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.062 seconds
[2021-08-19 16:51:30,511] {scheduler_job.py:181} INFO - Started process (PID=17564) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:51:30,512] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:51:30,512] {logging_mixin.py:104} INFO - [2021-08-19 16:51:30,512] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:51:30,521] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:51:30,543] {logging_mixin.py:104} INFO - [2021-08-19 16:51:30,543] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:51:30,555] {logging_mixin.py:104} INFO - [2021-08-19 16:51:30,554] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T15:30:00+00:00
[2021-08-19 16:51:30,565] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.057 seconds
[2021-08-19 16:52:00,949] {scheduler_job.py:181} INFO - Started process (PID=17628) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:52:00,950] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:52:00,951] {logging_mixin.py:104} INFO - [2021-08-19 16:52:00,951] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:52:00,963] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:52:00,984] {logging_mixin.py:104} INFO - [2021-08-19 16:52:00,984] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:52:00,998] {logging_mixin.py:104} INFO - [2021-08-19 16:52:00,997] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T15:30:00+00:00
[2021-08-19 16:52:01,011] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.064 seconds
[2021-08-19 16:52:31,572] {scheduler_job.py:181} INFO - Started process (PID=17691) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:52:31,574] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:52:31,574] {logging_mixin.py:104} INFO - [2021-08-19 16:52:31,574] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:52:31,586] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:52:31,607] {logging_mixin.py:104} INFO - [2021-08-19 16:52:31,607] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:52:31,620] {logging_mixin.py:104} INFO - [2021-08-19 16:52:31,619] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T15:30:00+00:00
[2021-08-19 16:52:31,634] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.065 seconds
[2021-08-19 16:53:02,096] {scheduler_job.py:181} INFO - Started process (PID=17744) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:53:02,098] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:53:02,098] {logging_mixin.py:104} INFO - [2021-08-19 16:53:02,098] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:53:02,109] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:53:02,128] {logging_mixin.py:104} INFO - [2021-08-19 16:53:02,127] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:53:02,139] {logging_mixin.py:104} INFO - [2021-08-19 16:53:02,139] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T15:30:00+00:00
[2021-08-19 16:53:02,150] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.057 seconds
[2021-08-19 16:53:32,736] {scheduler_job.py:181} INFO - Started process (PID=17806) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:53:32,737] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:53:32,738] {logging_mixin.py:104} INFO - [2021-08-19 16:53:32,738] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:53:32,748] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:53:32,767] {logging_mixin.py:104} INFO - [2021-08-19 16:53:32,767] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:53:32,778] {logging_mixin.py:104} INFO - [2021-08-19 16:53:32,778] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T15:30:00+00:00
[2021-08-19 16:53:32,795] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.061 seconds
[2021-08-19 16:54:03,148] {scheduler_job.py:181} INFO - Started process (PID=17871) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:54:03,150] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:54:03,150] {logging_mixin.py:104} INFO - [2021-08-19 16:54:03,150] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:54:03,160] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:54:03,178] {logging_mixin.py:104} INFO - [2021-08-19 16:54:03,178] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:54:03,190] {logging_mixin.py:104} INFO - [2021-08-19 16:54:03,190] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T15:30:00+00:00
[2021-08-19 16:54:03,201] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.057 seconds
[2021-08-19 16:54:33,781] {scheduler_job.py:181} INFO - Started process (PID=17940) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:54:33,782] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:54:33,783] {logging_mixin.py:104} INFO - [2021-08-19 16:54:33,783] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:54:33,797] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:54:33,819] {logging_mixin.py:104} INFO - [2021-08-19 16:54:33,819] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:54:33,837] {logging_mixin.py:104} INFO - [2021-08-19 16:54:33,837] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T15:30:00+00:00
[2021-08-19 16:54:33,852] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.074 seconds
[2021-08-19 16:55:04,511] {scheduler_job.py:181} INFO - Started process (PID=17993) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:55:04,512] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:55:04,513] {logging_mixin.py:104} INFO - [2021-08-19 16:55:04,513] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:55:04,527] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:55:04,547] {logging_mixin.py:104} INFO - [2021-08-19 16:55:04,547] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:55:04,558] {logging_mixin.py:104} INFO - [2021-08-19 16:55:04,558] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T16:45:00+00:00
[2021-08-19 16:55:04,568] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.061 seconds
[2021-08-19 16:55:35,170] {scheduler_job.py:181} INFO - Started process (PID=18058) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:55:35,172] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:55:35,173] {logging_mixin.py:104} INFO - [2021-08-19 16:55:35,173] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:55:35,185] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:55:35,206] {logging_mixin.py:104} INFO - [2021-08-19 16:55:35,206] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:55:35,217] {logging_mixin.py:104} INFO - [2021-08-19 16:55:35,217] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T16:45:00+00:00
[2021-08-19 16:55:35,227] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.061 seconds
[2021-08-19 16:56:05,751] {scheduler_job.py:181} INFO - Started process (PID=18123) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:56:05,753] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:56:05,753] {logging_mixin.py:104} INFO - [2021-08-19 16:56:05,753] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:56:05,766] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:56:05,787] {logging_mixin.py:104} INFO - [2021-08-19 16:56:05,786] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:56:05,800] {logging_mixin.py:104} INFO - [2021-08-19 16:56:05,800] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T16:45:00+00:00
[2021-08-19 16:56:05,813] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.065 seconds
[2021-08-19 16:56:36,332] {scheduler_job.py:181} INFO - Started process (PID=18176) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:56:36,333] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:56:36,334] {logging_mixin.py:104} INFO - [2021-08-19 16:56:36,334] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:56:36,343] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:56:36,363] {logging_mixin.py:104} INFO - [2021-08-19 16:56:36,363] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:56:36,375] {logging_mixin.py:104} INFO - [2021-08-19 16:56:36,375] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T16:45:00+00:00
[2021-08-19 16:56:36,388] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.060 seconds
[2021-08-19 16:57:06,766] {scheduler_job.py:181} INFO - Started process (PID=18239) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:57:06,767] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:57:06,768] {logging_mixin.py:104} INFO - [2021-08-19 16:57:06,768] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:57:06,781] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:57:06,800] {logging_mixin.py:104} INFO - [2021-08-19 16:57:06,800] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:57:06,812] {logging_mixin.py:104} INFO - [2021-08-19 16:57:06,812] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T16:45:00+00:00
[2021-08-19 16:57:06,823] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.060 seconds
[2021-08-19 16:57:37,325] {scheduler_job.py:181} INFO - Started process (PID=18303) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:57:37,326] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:57:37,327] {logging_mixin.py:104} INFO - [2021-08-19 16:57:37,327] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:57:37,335] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:57:37,353] {logging_mixin.py:104} INFO - [2021-08-19 16:57:37,353] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:57:37,366] {logging_mixin.py:104} INFO - [2021-08-19 16:57:37,366] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T16:45:00+00:00
[2021-08-19 16:57:37,376] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.056 seconds
[2021-08-19 16:58:07,918] {scheduler_job.py:181} INFO - Started process (PID=18357) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:58:07,919] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:58:07,919] {logging_mixin.py:104} INFO - [2021-08-19 16:58:07,919] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:58:07,928] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:58:07,946] {logging_mixin.py:104} INFO - [2021-08-19 16:58:07,946] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:58:07,959] {logging_mixin.py:104} INFO - [2021-08-19 16:58:07,959] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T16:45:00+00:00
[2021-08-19 16:58:07,972] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.058 seconds
[2021-08-19 16:58:38,311] {scheduler_job.py:181} INFO - Started process (PID=18421) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:58:38,312] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:58:38,313] {logging_mixin.py:104} INFO - [2021-08-19 16:58:38,313] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:58:38,326] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:58:38,350] {logging_mixin.py:104} INFO - [2021-08-19 16:58:38,349] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:58:38,361] {logging_mixin.py:104} INFO - [2021-08-19 16:58:38,361] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T16:45:00+00:00
[2021-08-19 16:58:38,370] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.065 seconds
[2021-08-19 16:59:08,483] {scheduler_job.py:181} INFO - Started process (PID=18485) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:59:08,484] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:59:08,485] {logging_mixin.py:104} INFO - [2021-08-19 16:59:08,485] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:59:08,496] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:59:08,520] {logging_mixin.py:104} INFO - [2021-08-19 16:59:08,520] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:59:08,535] {logging_mixin.py:104} INFO - [2021-08-19 16:59:08,535] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T16:45:00+00:00
[2021-08-19 16:59:08,547] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.069 seconds
[2021-08-19 16:59:39,117] {scheduler_job.py:181} INFO - Started process (PID=18539) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 16:59:39,120] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 16:59:39,121] {logging_mixin.py:104} INFO - [2021-08-19 16:59:39,121] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:59:39,137] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 16:59:39,162] {logging_mixin.py:104} INFO - [2021-08-19 16:59:39,162] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 16:59:39,182] {logging_mixin.py:104} INFO - [2021-08-19 16:59:39,182] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T16:45:00+00:00
[2021-08-19 16:59:39,197] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.084 seconds
[2021-08-19 17:00:09,620] {scheduler_job.py:181} INFO - Started process (PID=18610) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:00:09,621] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:00:09,621] {logging_mixin.py:104} INFO - [2021-08-19 17:00:09,621] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:00:09,630] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:00:09,649] {logging_mixin.py:104} INFO - [2021-08-19 17:00:09,649] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 17:00:09,661] {logging_mixin.py:104} INFO - [2021-08-19 17:00:09,661] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T17:00:00+00:00
[2021-08-19 17:00:09,673] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.056 seconds
[2021-08-19 17:00:40,088] {scheduler_job.py:181} INFO - Started process (PID=18674) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:00:40,088] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:00:40,089] {logging_mixin.py:104} INFO - [2021-08-19 17:00:40,089] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:00:40,096] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:00:40,116] {logging_mixin.py:104} INFO - [2021-08-19 17:00:40,115] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 17:00:40,127] {logging_mixin.py:104} INFO - [2021-08-19 17:00:40,127] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T17:00:00+00:00
[2021-08-19 17:00:40,138] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.053 seconds
[2021-08-19 17:01:10,500] {scheduler_job.py:181} INFO - Started process (PID=18738) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:01:10,502] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:01:10,502] {logging_mixin.py:104} INFO - [2021-08-19 17:01:10,502] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:01:10,514] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:01:10,533] {logging_mixin.py:104} INFO - [2021-08-19 17:01:10,533] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 17:01:10,544] {logging_mixin.py:104} INFO - [2021-08-19 17:01:10,544] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T17:00:00+00:00
[2021-08-19 17:01:10,555] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.058 seconds
[2021-08-19 17:01:40,860] {scheduler_job.py:181} INFO - Started process (PID=18791) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:01:40,861] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:01:40,862] {logging_mixin.py:104} INFO - [2021-08-19 17:01:40,862] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:01:40,870] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:01:40,890] {logging_mixin.py:104} INFO - [2021-08-19 17:01:40,890] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 17:01:40,902] {logging_mixin.py:104} INFO - [2021-08-19 17:01:40,902] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T17:00:00+00:00
[2021-08-19 17:01:40,913] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.056 seconds
[2021-08-19 17:02:11,210] {scheduler_job.py:181} INFO - Started process (PID=18856) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:02:11,211] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:02:11,212] {logging_mixin.py:104} INFO - [2021-08-19 17:02:11,212] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:02:11,221] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:02:11,239] {logging_mixin.py:104} INFO - [2021-08-19 17:02:11,239] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 17:02:11,250] {logging_mixin.py:104} INFO - [2021-08-19 17:02:11,250] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T17:00:00+00:00
[2021-08-19 17:02:11,260] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.053 seconds
[2021-08-19 17:02:41,612] {scheduler_job.py:181} INFO - Started process (PID=18921) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:02:41,613] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:02:41,614] {logging_mixin.py:104} INFO - [2021-08-19 17:02:41,614] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:02:41,625] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:02:41,644] {logging_mixin.py:104} INFO - [2021-08-19 17:02:41,644] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 17:02:41,653] {logging_mixin.py:104} INFO - [2021-08-19 17:02:41,653] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T17:00:00+00:00
[2021-08-19 17:02:41,665] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.056 seconds
[2021-08-19 17:03:12,056] {scheduler_job.py:181} INFO - Started process (PID=18974) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:03:12,057] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:03:12,058] {logging_mixin.py:104} INFO - [2021-08-19 17:03:12,058] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:03:12,067] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:03:12,084] {logging_mixin.py:104} INFO - [2021-08-19 17:03:12,083] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 17:03:12,095] {logging_mixin.py:104} INFO - [2021-08-19 17:03:12,094] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T17:00:00+00:00
[2021-08-19 17:03:12,106] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.052 seconds
[2021-08-19 17:03:42,429] {scheduler_job.py:181} INFO - Started process (PID=19037) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:03:42,430] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:03:42,430] {logging_mixin.py:104} INFO - [2021-08-19 17:03:42,430] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:03:42,440] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:03:42,460] {logging_mixin.py:104} INFO - [2021-08-19 17:03:42,460] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 17:03:42,473] {logging_mixin.py:104} INFO - [2021-08-19 17:03:42,473] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T17:00:00+00:00
[2021-08-19 17:03:42,482] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.057 seconds
[2021-08-19 17:04:12,872] {scheduler_job.py:181} INFO - Started process (PID=19101) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:04:12,873] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:04:12,873] {logging_mixin.py:104} INFO - [2021-08-19 17:04:12,873] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:04:12,883] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:04:12,902] {logging_mixin.py:104} INFO - [2021-08-19 17:04:12,902] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 17:04:12,913] {logging_mixin.py:104} INFO - [2021-08-19 17:04:12,913] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T17:00:00+00:00
[2021-08-19 17:04:12,923] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.055 seconds
[2021-08-19 17:04:43,390] {scheduler_job.py:181} INFO - Started process (PID=19154) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:04:43,391] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:04:43,391] {logging_mixin.py:104} INFO - [2021-08-19 17:04:43,391] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:04:43,400] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:04:43,422] {logging_mixin.py:104} INFO - [2021-08-19 17:04:43,422] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 17:04:43,433] {logging_mixin.py:104} INFO - [2021-08-19 17:04:43,433] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T17:00:00+00:00
[2021-08-19 17:04:43,445] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.058 seconds
[2021-08-19 17:05:13,874] {scheduler_job.py:181} INFO - Started process (PID=19218) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:05:13,875] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:05:13,876] {logging_mixin.py:104} INFO - [2021-08-19 17:05:13,875] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:05:13,888] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:05:13,912] {logging_mixin.py:104} INFO - [2021-08-19 17:05:13,912] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 17:05:13,926] {logging_mixin.py:104} INFO - [2021-08-19 17:05:13,926] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T17:00:00+00:00
[2021-08-19 17:05:13,935] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.066 seconds
[2021-08-19 17:05:44,400] {scheduler_job.py:181} INFO - Started process (PID=19283) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:05:44,401] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:05:44,401] {logging_mixin.py:104} INFO - [2021-08-19 17:05:44,401] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:05:44,410] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:05:44,428] {logging_mixin.py:104} INFO - [2021-08-19 17:05:44,428] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 17:05:44,440] {logging_mixin.py:104} INFO - [2021-08-19 17:05:44,439] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T17:00:00+00:00
[2021-08-19 17:05:44,451] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.054 seconds
[2021-08-19 17:06:14,797] {scheduler_job.py:181} INFO - Started process (PID=19336) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:06:14,798] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:06:14,798] {logging_mixin.py:104} INFO - [2021-08-19 17:06:14,798] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:06:14,809] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:06:14,830] {logging_mixin.py:104} INFO - [2021-08-19 17:06:14,830] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 17:06:14,845] {logging_mixin.py:104} INFO - [2021-08-19 17:06:14,845] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T17:00:00+00:00
[2021-08-19 17:06:14,857] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.064 seconds
[2021-08-19 17:06:45,398] {scheduler_job.py:181} INFO - Started process (PID=19400) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:06:45,399] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:06:45,400] {logging_mixin.py:104} INFO - [2021-08-19 17:06:45,400] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:06:45,411] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:06:45,433] {logging_mixin.py:104} INFO - [2021-08-19 17:06:45,433] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 17:06:45,448] {logging_mixin.py:104} INFO - [2021-08-19 17:06:45,448] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T17:00:00+00:00
[2021-08-19 17:06:45,461] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.065 seconds
[2021-08-19 17:07:15,838] {scheduler_job.py:181} INFO - Started process (PID=19462) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:07:15,839] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:07:15,839] {logging_mixin.py:104} INFO - [2021-08-19 17:07:15,839] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:07:15,849] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:07:15,870] {logging_mixin.py:104} INFO - [2021-08-19 17:07:15,870] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 17:07:15,882] {logging_mixin.py:104} INFO - [2021-08-19 17:07:15,882] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T17:00:00+00:00
[2021-08-19 17:07:15,892] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.057 seconds
[2021-08-19 17:07:46,382] {scheduler_job.py:181} INFO - Started process (PID=19526) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:07:46,383] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:07:46,384] {logging_mixin.py:104} INFO - [2021-08-19 17:07:46,384] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:07:46,393] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:07:46,412] {logging_mixin.py:104} INFO - [2021-08-19 17:07:46,412] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 17:07:46,425] {logging_mixin.py:104} INFO - [2021-08-19 17:07:46,425] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T17:00:00+00:00
[2021-08-19 17:07:46,434] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.055 seconds
[2021-08-19 17:08:16,822] {scheduler_job.py:181} INFO - Started process (PID=19580) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:08:16,823] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:08:16,823] {logging_mixin.py:104} INFO - [2021-08-19 17:08:16,823] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:08:16,835] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:08:16,855] {logging_mixin.py:104} INFO - [2021-08-19 17:08:16,854] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 17:08:16,866] {logging_mixin.py:104} INFO - [2021-08-19 17:08:16,866] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T17:00:00+00:00
[2021-08-19 17:08:16,876] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.057 seconds
[2021-08-19 17:08:47,128] {scheduler_job.py:181} INFO - Started process (PID=19644) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:08:47,129] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:08:47,129] {logging_mixin.py:104} INFO - [2021-08-19 17:08:47,129] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:08:47,140] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:08:47,158] {logging_mixin.py:104} INFO - [2021-08-19 17:08:47,158] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 17:08:47,169] {logging_mixin.py:104} INFO - [2021-08-19 17:08:47,169] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T17:00:00+00:00
[2021-08-19 17:08:47,178] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.053 seconds
[2021-08-19 17:09:17,643] {scheduler_job.py:181} INFO - Started process (PID=19706) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:09:17,644] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:09:17,645] {logging_mixin.py:104} INFO - [2021-08-19 17:09:17,645] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:09:17,658] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:09:17,680] {logging_mixin.py:104} INFO - [2021-08-19 17:09:17,680] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 17:09:17,694] {logging_mixin.py:104} INFO - [2021-08-19 17:09:17,693] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T17:00:00+00:00
[2021-08-19 17:09:17,707] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.067 seconds
[2021-08-19 17:09:48,160] {scheduler_job.py:181} INFO - Started process (PID=19759) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:09:48,162] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:09:48,163] {logging_mixin.py:104} INFO - [2021-08-19 17:09:48,163] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:09:48,174] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:09:48,196] {logging_mixin.py:104} INFO - [2021-08-19 17:09:48,196] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 17:09:48,209] {logging_mixin.py:104} INFO - [2021-08-19 17:09:48,209] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T17:00:00+00:00
[2021-08-19 17:09:48,222] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.066 seconds
[2021-08-19 17:10:18,718] {scheduler_job.py:181} INFO - Started process (PID=19824) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:10:18,720] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:10:18,720] {logging_mixin.py:104} INFO - [2021-08-19 17:10:18,720] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:10:18,730] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:10:18,749] {logging_mixin.py:104} INFO - [2021-08-19 17:10:18,749] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 17:10:18,763] {logging_mixin.py:104} INFO - [2021-08-19 17:10:18,763] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T17:00:00+00:00
[2021-08-19 17:10:18,775] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.059 seconds
[2021-08-19 17:10:49,161] {scheduler_job.py:181} INFO - Started process (PID=19887) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:10:49,162] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:10:49,163] {logging_mixin.py:104} INFO - [2021-08-19 17:10:49,162] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:10:49,174] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:10:49,195] {logging_mixin.py:104} INFO - [2021-08-19 17:10:49,195] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 17:10:49,205] {logging_mixin.py:104} INFO - [2021-08-19 17:10:49,205] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T17:00:00+00:00
[2021-08-19 17:10:49,215] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.058 seconds
[2021-08-19 17:11:19,650] {scheduler_job.py:181} INFO - Started process (PID=19939) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:11:19,652] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:11:19,652] {logging_mixin.py:104} INFO - [2021-08-19 17:11:19,652] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:11:19,663] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:11:19,685] {logging_mixin.py:104} INFO - [2021-08-19 17:11:19,685] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 17:11:19,697] {logging_mixin.py:104} INFO - [2021-08-19 17:11:19,697] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T17:00:00+00:00
[2021-08-19 17:11:19,708] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.063 seconds
[2021-08-19 17:11:50,100] {scheduler_job.py:181} INFO - Started process (PID=20003) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:11:50,101] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:11:50,101] {logging_mixin.py:104} INFO - [2021-08-19 17:11:50,101] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:11:50,111] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:11:50,132] {logging_mixin.py:104} INFO - [2021-08-19 17:11:50,132] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 17:11:50,145] {logging_mixin.py:104} INFO - [2021-08-19 17:11:50,145] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T17:00:00+00:00
[2021-08-19 17:11:50,160] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.062 seconds
[2021-08-19 17:12:20,573] {scheduler_job.py:181} INFO - Started process (PID=20066) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:12:20,575] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:12:20,575] {logging_mixin.py:104} INFO - [2021-08-19 17:12:20,575] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:12:20,585] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:12:20,602] {logging_mixin.py:104} INFO - [2021-08-19 17:12:20,602] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 17:12:20,613] {logging_mixin.py:104} INFO - [2021-08-19 17:12:20,613] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T17:00:00+00:00
[2021-08-19 17:12:20,622] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.052 seconds
[2021-08-19 17:12:51,023] {scheduler_job.py:181} INFO - Started process (PID=20118) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:12:51,024] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:12:51,025] {logging_mixin.py:104} INFO - [2021-08-19 17:12:51,025] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:12:51,038] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:12:51,070] {logging_mixin.py:104} INFO - [2021-08-19 17:12:51,070] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 17:12:51,081] {logging_mixin.py:104} INFO - [2021-08-19 17:12:51,081] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T17:00:00+00:00
[2021-08-19 17:12:51,094] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.075 seconds
[2021-08-19 17:13:21,503] {scheduler_job.py:181} INFO - Started process (PID=20182) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:13:21,504] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:13:21,504] {logging_mixin.py:104} INFO - [2021-08-19 17:13:21,504] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:13:21,514] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:13:21,536] {logging_mixin.py:104} INFO - [2021-08-19 17:13:21,536] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 17:13:21,549] {logging_mixin.py:104} INFO - [2021-08-19 17:13:21,548] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T17:00:00+00:00
[2021-08-19 17:13:21,560] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.062 seconds
[2021-08-19 17:13:55,156] {scheduler_job.py:181} INFO - Started process (PID=24) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:13:55,157] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:13:55,158] {logging_mixin.py:104} INFO - [2021-08-19 17:13:55,157] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:13:55,180] {logging_mixin.py:104} INFO - [2021-08-19 17:13:55,179] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 10, in <module>
    filehand = logging.FileHandler('crawl_url/logging_test.log')
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
PermissionError: [Errno 13] Permission denied: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:13:55,181] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:13:55,215] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.062 seconds
[2021-08-19 17:14:25,275] {scheduler_job.py:181} INFO - Started process (PID=76) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:14:25,277] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:14:25,277] {logging_mixin.py:104} INFO - [2021-08-19 17:14:25,277] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:14:25,297] {logging_mixin.py:104} INFO - [2021-08-19 17:14:25,295] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 10, in <module>
    filehand = logging.FileHandler('crawl_url/logging_test.log')
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
PermissionError: [Errno 13] Permission denied: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:14:25,298] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:14:25,333] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.063 seconds
[2021-08-19 17:14:55,806] {scheduler_job.py:181} INFO - Started process (PID=139) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:14:55,807] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:14:55,808] {logging_mixin.py:104} INFO - [2021-08-19 17:14:55,808] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:14:55,819] {logging_mixin.py:104} INFO - [2021-08-19 17:14:55,818] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 10, in <module>
    filehand = logging.FileHandler('crawl_url/logging_test.log')
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
PermissionError: [Errno 13] Permission denied: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:14:55,819] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:14:55,840] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.036 seconds
[2021-08-19 17:15:02,344] {scheduler_job.py:181} INFO - Started process (PID=181) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:15:02,345] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:15:02,345] {logging_mixin.py:104} INFO - [2021-08-19 17:15:02,345] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:15:02,357] {logging_mixin.py:104} INFO - [2021-08-19 17:15:02,355] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 10, in <module>
    filehand = logging.FileHandler('crawl_url/logging_test.log')
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
PermissionError: [Errno 13] Permission denied: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:15:02,357] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:15:02,373] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.033 seconds
[2021-08-19 17:15:32,857] {scheduler_job.py:181} INFO - Started process (PID=234) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:15:32,858] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:15:32,859] {logging_mixin.py:104} INFO - [2021-08-19 17:15:32,859] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:15:32,870] {logging_mixin.py:104} INFO - [2021-08-19 17:15:32,869] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 10, in <module>
    filehand = logging.FileHandler('crawl_url/logging_test.log')
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
PermissionError: [Errno 13] Permission denied: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:15:32,871] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:15:32,888] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.033 seconds
[2021-08-19 17:16:03,732] {scheduler_job.py:181} INFO - Started process (PID=298) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:16:03,733] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:16:03,733] {logging_mixin.py:104} INFO - [2021-08-19 17:16:03,733] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:16:03,745] {logging_mixin.py:104} INFO - [2021-08-19 17:16:03,744] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 10, in <module>
    filehand = logging.FileHandler('crawl_url/logging_test.log')
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
PermissionError: [Errno 13] Permission denied: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:16:03,745] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:16:03,770] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.041 seconds
[2021-08-19 17:16:34,689] {scheduler_job.py:181} INFO - Started process (PID=362) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:16:34,694] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:16:34,695] {logging_mixin.py:104} INFO - [2021-08-19 17:16:34,695] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:16:34,702] {logging_mixin.py:104} INFO - [2021-08-19 17:16:34,701] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 10, in <module>
    filehand = logging.FileHandler('crawl_url/logging_test.log')
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
PermissionError: [Errno 13] Permission denied: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:16:34,702] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:16:34,724] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.038 seconds
[2021-08-19 17:17:05,438] {scheduler_job.py:181} INFO - Started process (PID=415) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:17:05,438] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:17:05,439] {logging_mixin.py:104} INFO - [2021-08-19 17:17:05,439] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:17:05,449] {logging_mixin.py:104} INFO - [2021-08-19 17:17:05,447] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 10, in <module>
    filehand = logging.FileHandler('crawl_url/logging_test.log')
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
PermissionError: [Errno 13] Permission denied: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:17:05,449] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:17:05,472] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.037 seconds
[2021-08-19 17:17:36,074] {scheduler_job.py:181} INFO - Started process (PID=478) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:17:36,075] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:17:36,076] {logging_mixin.py:104} INFO - [2021-08-19 17:17:36,076] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:17:36,084] {logging_mixin.py:104} INFO - [2021-08-19 17:17:36,084] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 10, in <module>
    filehand = logging.FileHandler('crawl_url/logging_test.log')
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
PermissionError: [Errno 13] Permission denied: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:17:36,085] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:17:36,101] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.031 seconds
[2021-08-19 17:18:06,936] {scheduler_job.py:181} INFO - Started process (PID=542) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:18:06,937] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:18:06,938] {logging_mixin.py:104} INFO - [2021-08-19 17:18:06,938] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:18:06,946] {logging_mixin.py:104} INFO - [2021-08-19 17:18:06,945] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 10, in <module>
    filehand = logging.FileHandler('crawl_url/logging_test.log')
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
PermissionError: [Errno 13] Permission denied: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:18:06,946] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:18:06,964] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.030 seconds
[2021-08-19 17:18:37,577] {scheduler_job.py:181} INFO - Started process (PID=606) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:18:37,578] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:18:37,578] {logging_mixin.py:104} INFO - [2021-08-19 17:18:37,578] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:18:37,587] {logging_mixin.py:104} INFO - [2021-08-19 17:18:37,586] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 10, in <module>
    filehand = logging.FileHandler('crawl_url/logging_test.log')
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
PermissionError: [Errno 13] Permission denied: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:18:37,587] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:18:37,607] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.032 seconds
[2021-08-19 17:19:08,327] {scheduler_job.py:181} INFO - Started process (PID=659) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:19:08,328] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:19:08,328] {logging_mixin.py:104} INFO - [2021-08-19 17:19:08,328] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:19:08,335] {logging_mixin.py:104} INFO - [2021-08-19 17:19:08,335] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 10, in <module>
    filehand = logging.FileHandler('crawl_url/logging_test.log')
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
PermissionError: [Errno 13] Permission denied: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:19:08,336] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:19:08,354] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.030 seconds
[2021-08-19 17:19:38,458] {scheduler_job.py:181} INFO - Started process (PID=724) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:19:38,459] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:19:38,459] {logging_mixin.py:104} INFO - [2021-08-19 17:19:38,459] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:19:38,467] {logging_mixin.py:104} INFO - [2021-08-19 17:19:38,466] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 10, in <module>
    filehand = logging.FileHandler('crawl_url/logging_test.log')
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
PermissionError: [Errno 13] Permission denied: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:19:38,467] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:19:38,485] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.030 seconds
[2021-08-19 17:20:09,192] {scheduler_job.py:181} INFO - Started process (PID=788) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:20:09,193] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:20:09,193] {logging_mixin.py:104} INFO - [2021-08-19 17:20:09,193] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:20:09,202] {logging_mixin.py:104} INFO - [2021-08-19 17:20:09,200] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 10, in <module>
    filehand = logging.FileHandler('crawl_url/logging_test.log')
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
PermissionError: [Errno 13] Permission denied: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:20:09,202] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:20:09,223] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.034 seconds
[2021-08-19 17:20:39,987] {scheduler_job.py:181} INFO - Started process (PID=842) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:20:39,988] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:20:39,989] {logging_mixin.py:104} INFO - [2021-08-19 17:20:39,989] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:20:39,998] {logging_mixin.py:104} INFO - [2021-08-19 17:20:39,998] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler('crawl_url/logging_test.log')
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
PermissionError: [Errno 13] Permission denied: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:20:39,999] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:20:40,019] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.034 seconds
[2021-08-19 17:21:10,660] {scheduler_job.py:181} INFO - Started process (PID=905) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:21:10,662] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:21:10,662] {logging_mixin.py:104} INFO - [2021-08-19 17:21:10,662] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:21:10,673] {logging_mixin.py:104} INFO - [2021-08-19 17:21:10,673] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler('crawl_url/logging_test.log')
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
PermissionError: [Errno 13] Permission denied: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:21:10,674] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:21:10,692] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.035 seconds
[2021-08-19 17:21:41,355] {scheduler_job.py:181} INFO - Started process (PID=967) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:21:41,356] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:21:41,356] {logging_mixin.py:104} INFO - [2021-08-19 17:21:41,356] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:21:41,365] {logging_mixin.py:104} INFO - [2021-08-19 17:21:41,365] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
PermissionError: [Errno 13] Permission denied: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:21:41,366] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:21:41,384] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.032 seconds
[2021-08-19 17:22:12,053] {scheduler_job.py:181} INFO - Started process (PID=1031) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:22:12,054] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:22:12,055] {logging_mixin.py:104} INFO - [2021-08-19 17:22:12,054] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:22:12,063] {logging_mixin.py:104} INFO - [2021-08-19 17:22:12,062] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
PermissionError: [Errno 13] Permission denied: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:22:12,064] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:22:12,084] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.033 seconds
[2021-08-19 17:22:42,706] {scheduler_job.py:181} INFO - Started process (PID=1083) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:22:42,707] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:22:42,707] {logging_mixin.py:104} INFO - [2021-08-19 17:22:42,707] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:22:42,714] {logging_mixin.py:104} INFO - [2021-08-19 17:22:42,713] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
PermissionError: [Errno 13] Permission denied: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:22:42,714] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:22:42,733] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.030 seconds
[2021-08-19 17:23:13,586] {scheduler_job.py:181} INFO - Started process (PID=1147) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:23:13,587] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:23:13,587] {logging_mixin.py:104} INFO - [2021-08-19 17:23:13,587] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:23:13,599] {logging_mixin.py:104} INFO - [2021-08-19 17:23:13,598] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
PermissionError: [Errno 13] Permission denied: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:23:13,599] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:23:13,615] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.032 seconds
[2021-08-19 17:23:44,227] {scheduler_job.py:181} INFO - Started process (PID=1210) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:23:44,228] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:23:44,229] {logging_mixin.py:104} INFO - [2021-08-19 17:23:44,229] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:23:44,239] {logging_mixin.py:104} INFO - [2021-08-19 17:23:44,238] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
PermissionError: [Errno 13] Permission denied: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:23:44,240] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:23:44,258] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.033 seconds
[2021-08-19 17:24:14,377] {scheduler_job.py:181} INFO - Started process (PID=1264) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:24:14,378] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:24:14,378] {logging_mixin.py:104} INFO - [2021-08-19 17:24:14,378] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:24:14,386] {logging_mixin.py:104} INFO - [2021-08-19 17:24:14,384] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
PermissionError: [Errno 13] Permission denied: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:24:14,386] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:24:14,406] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.031 seconds
[2021-08-19 17:24:45,069] {scheduler_job.py:181} INFO - Started process (PID=1327) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:24:45,070] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:24:45,071] {logging_mixin.py:104} INFO - [2021-08-19 17:24:45,071] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:24:45,083] {logging_mixin.py:104} INFO - [2021-08-19 17:24:45,082] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
PermissionError: [Errno 13] Permission denied: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:24:45,083] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:24:45,104] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.040 seconds
[2021-08-19 17:25:15,799] {scheduler_job.py:181} INFO - Started process (PID=1392) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:25:15,799] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:25:15,800] {logging_mixin.py:104} INFO - [2021-08-19 17:25:15,800] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:25:15,808] {logging_mixin.py:104} INFO - [2021-08-19 17:25:15,808] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
PermissionError: [Errno 13] Permission denied: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:25:15,809] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:25:15,826] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.031 seconds
[2021-08-19 17:25:46,460] {scheduler_job.py:181} INFO - Started process (PID=1446) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:25:46,461] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:25:46,461] {logging_mixin.py:104} INFO - [2021-08-19 17:25:46,461] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:25:46,469] {logging_mixin.py:104} INFO - [2021-08-19 17:25:46,468] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
PermissionError: [Errno 13] Permission denied: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:25:46,469] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:25:46,490] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.033 seconds
[2021-08-19 17:26:17,108] {scheduler_job.py:181} INFO - Started process (PID=1510) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:26:17,110] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:26:17,110] {logging_mixin.py:104} INFO - [2021-08-19 17:26:17,110] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:26:17,118] {logging_mixin.py:104} INFO - [2021-08-19 17:26:17,117] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
PermissionError: [Errno 13] Permission denied: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:26:17,118] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:26:17,136] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.030 seconds
[2021-08-19 17:26:47,684] {scheduler_job.py:181} INFO - Started process (PID=1573) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:26:47,685] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:26:47,686] {logging_mixin.py:104} INFO - [2021-08-19 17:26:47,686] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:26:47,696] {logging_mixin.py:104} INFO - [2021-08-19 17:26:47,695] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
PermissionError: [Errno 13] Permission denied: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:26:47,697] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:26:47,718] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.037 seconds
[2021-08-19 17:27:18,150] {scheduler_job.py:181} INFO - Started process (PID=1635) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:27:18,151] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:27:18,151] {logging_mixin.py:104} INFO - [2021-08-19 17:27:18,151] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:27:18,159] {logging_mixin.py:104} INFO - [2021-08-19 17:27:18,158] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
PermissionError: [Errno 13] Permission denied: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:27:18,159] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:27:18,179] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.031 seconds
[2021-08-19 17:27:48,988] {scheduler_job.py:181} INFO - Started process (PID=1687) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:27:48,989] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:27:48,989] {logging_mixin.py:104} INFO - [2021-08-19 17:27:48,989] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:27:48,997] {logging_mixin.py:104} INFO - [2021-08-19 17:27:48,995] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
PermissionError: [Errno 13] Permission denied: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:27:48,997] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:27:49,017] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.032 seconds
[2021-08-19 17:28:08,919] {scheduler_job.py:181} INFO - Started process (PID=26) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:28:08,927] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:28:08,937] {logging_mixin.py:104} INFO - [2021-08-19 17:28:08,935] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:28:08,958] {logging_mixin.py:104} INFO - [2021-08-19 17:28:08,954] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:28:08,958] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:28:08,983] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.068 seconds
[2021-08-19 17:28:39,934] {scheduler_job.py:181} INFO - Started process (PID=91) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:28:39,935] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:28:39,936] {logging_mixin.py:104} INFO - [2021-08-19 17:28:39,936] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:28:39,951] {logging_mixin.py:104} INFO - [2021-08-19 17:28:39,948] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:28:39,951] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:28:39,974] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.044 seconds
[2021-08-19 17:29:10,830] {scheduler_job.py:181} INFO - Started process (PID=155) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:29:10,831] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:29:10,832] {logging_mixin.py:104} INFO - [2021-08-19 17:29:10,832] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:29:10,842] {logging_mixin.py:104} INFO - [2021-08-19 17:29:10,841] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:29:10,842] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:29:10,861] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.034 seconds
[2021-08-19 17:29:41,406] {scheduler_job.py:181} INFO - Started process (PID=207) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:29:41,407] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:29:41,408] {logging_mixin.py:104} INFO - [2021-08-19 17:29:41,408] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:29:41,417] {logging_mixin.py:104} INFO - [2021-08-19 17:29:41,416] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:29:41,417] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:29:41,435] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.031 seconds
[2021-08-19 17:30:01,661] {scheduler_job.py:181} INFO - Started process (PID=259) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:30:01,663] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:30:01,664] {logging_mixin.py:104} INFO - [2021-08-19 17:30:01,663] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:30:01,674] {logging_mixin.py:104} INFO - [2021-08-19 17:30:01,672] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:30:01,674] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:30:01,693] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.035 seconds
[2021-08-19 17:30:32,317] {scheduler_job.py:181} INFO - Started process (PID=321) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:30:32,318] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:30:32,318] {logging_mixin.py:104} INFO - [2021-08-19 17:30:32,318] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:30:32,328] {logging_mixin.py:104} INFO - [2021-08-19 17:30:32,327] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:30:32,329] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:30:32,352] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.039 seconds
[2021-08-19 17:31:03,030] {scheduler_job.py:181} INFO - Started process (PID=381) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:31:03,032] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:31:03,034] {logging_mixin.py:104} INFO - [2021-08-19 17:31:03,033] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:31:03,042] {logging_mixin.py:104} INFO - [2021-08-19 17:31:03,041] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:31:03,042] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:31:03,064] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.037 seconds
[2021-08-19 17:31:33,708] {scheduler_job.py:181} INFO - Started process (PID=436) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:31:33,709] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:31:33,709] {logging_mixin.py:104} INFO - [2021-08-19 17:31:33,709] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:31:33,717] {logging_mixin.py:104} INFO - [2021-08-19 17:31:33,716] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:31:33,718] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:31:33,735] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.031 seconds
[2021-08-19 17:32:04,272] {scheduler_job.py:181} INFO - Started process (PID=501) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:32:04,273] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:32:04,273] {logging_mixin.py:104} INFO - [2021-08-19 17:32:04,273] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:32:04,282] {logging_mixin.py:104} INFO - [2021-08-19 17:32:04,281] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:32:04,282] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:32:04,303] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.034 seconds
[2021-08-19 17:32:34,875] {scheduler_job.py:181} INFO - Started process (PID=565) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:32:34,875] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:32:34,876] {logging_mixin.py:104} INFO - [2021-08-19 17:32:34,876] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:32:34,884] {logging_mixin.py:104} INFO - [2021-08-19 17:32:34,883] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:32:34,884] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:32:34,905] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.033 seconds
[2021-08-19 17:33:04,936] {scheduler_job.py:181} INFO - Started process (PID=617) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:33:04,936] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:33:04,937] {logging_mixin.py:104} INFO - [2021-08-19 17:33:04,937] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:33:04,945] {logging_mixin.py:104} INFO - [2021-08-19 17:33:04,944] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:33:04,945] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:33:04,964] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.031 seconds
[2021-08-19 17:33:09,965] {scheduler_job.py:181} INFO - Started process (PID=629) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:33:09,965] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:33:09,966] {logging_mixin.py:104} INFO - [2021-08-19 17:33:09,966] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:33:09,976] {logging_mixin.py:104} INFO - [2021-08-19 17:33:09,975] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:33:09,976] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:33:09,996] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.034 seconds
[2021-08-19 17:33:40,590] {scheduler_job.py:181} INFO - Started process (PID=681) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:33:40,591] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:33:40,591] {logging_mixin.py:104} INFO - [2021-08-19 17:33:40,591] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:33:40,600] {logging_mixin.py:104} INFO - [2021-08-19 17:33:40,600] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:33:40,601] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:33:40,621] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.033 seconds
[2021-08-19 17:34:11,294] {scheduler_job.py:181} INFO - Started process (PID=743) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:34:11,295] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:34:11,295] {logging_mixin.py:104} INFO - [2021-08-19 17:34:11,295] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:34:11,304] {logging_mixin.py:104} INFO - [2021-08-19 17:34:11,303] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:34:11,304] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:34:11,329] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.038 seconds
[2021-08-19 17:34:42,056] {scheduler_job.py:181} INFO - Started process (PID=806) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:34:42,057] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:34:42,057] {logging_mixin.py:104} INFO - [2021-08-19 17:34:42,057] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:34:42,065] {logging_mixin.py:104} INFO - [2021-08-19 17:34:42,064] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:34:42,065] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:34:42,084] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.030 seconds
[2021-08-19 17:35:12,610] {scheduler_job.py:181} INFO - Started process (PID=870) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:35:12,611] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:35:12,612] {logging_mixin.py:104} INFO - [2021-08-19 17:35:12,612] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:35:12,621] {logging_mixin.py:104} INFO - [2021-08-19 17:35:12,620] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:35:12,621] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:35:12,643] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.036 seconds
[2021-08-19 17:35:43,177] {scheduler_job.py:181} INFO - Started process (PID=922) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:35:43,177] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:35:43,178] {logging_mixin.py:104} INFO - [2021-08-19 17:35:43,178] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:35:43,184] {logging_mixin.py:104} INFO - [2021-08-19 17:35:43,184] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:35:43,185] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:35:43,204] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.030 seconds
[2021-08-19 17:36:13,985] {scheduler_job.py:181} INFO - Started process (PID=986) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:36:13,985] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:36:13,986] {logging_mixin.py:104} INFO - [2021-08-19 17:36:13,986] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:36:13,995] {logging_mixin.py:104} INFO - [2021-08-19 17:36:13,994] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:36:13,995] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:36:14,015] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.032 seconds
[2021-08-19 17:36:44,671] {scheduler_job.py:181} INFO - Started process (PID=1050) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:36:44,672] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:36:44,672] {logging_mixin.py:104} INFO - [2021-08-19 17:36:44,672] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:36:44,685] {logging_mixin.py:104} INFO - [2021-08-19 17:36:44,683] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:36:44,685] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:36:44,706] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.039 seconds
[2021-08-19 17:37:15,450] {scheduler_job.py:181} INFO - Started process (PID=1103) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:37:15,450] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:37:15,451] {logging_mixin.py:104} INFO - [2021-08-19 17:37:15,451] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:37:15,459] {logging_mixin.py:104} INFO - [2021-08-19 17:37:15,458] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:37:15,459] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:37:15,479] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.032 seconds
[2021-08-19 17:37:46,196] {scheduler_job.py:181} INFO - Started process (PID=1167) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:37:46,197] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:37:46,198] {logging_mixin.py:104} INFO - [2021-08-19 17:37:46,198] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:37:46,206] {logging_mixin.py:104} INFO - [2021-08-19 17:37:46,205] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:37:46,206] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:37:46,230] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.036 seconds
[2021-08-19 17:38:16,800] {scheduler_job.py:181} INFO - Started process (PID=1231) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:38:16,801] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:38:16,802] {logging_mixin.py:104} INFO - [2021-08-19 17:38:16,802] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:38:16,812] {logging_mixin.py:104} INFO - [2021-08-19 17:38:16,811] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:38:16,812] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:38:16,832] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.035 seconds
[2021-08-19 17:38:47,669] {scheduler_job.py:181} INFO - Started process (PID=1294) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:38:47,670] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:38:47,671] {logging_mixin.py:104} INFO - [2021-08-19 17:38:47,670] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:38:47,681] {logging_mixin.py:104} INFO - [2021-08-19 17:38:47,680] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:38:47,682] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:38:47,701] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.034 seconds
[2021-08-19 17:39:18,562] {scheduler_job.py:181} INFO - Started process (PID=1347) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:39:18,563] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:39:18,564] {logging_mixin.py:104} INFO - [2021-08-19 17:39:18,563] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:39:18,577] {logging_mixin.py:104} INFO - [2021-08-19 17:39:18,576] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:39:18,577] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:39:18,598] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.039 seconds
[2021-08-19 17:39:49,219] {scheduler_job.py:181} INFO - Started process (PID=1410) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:39:49,220] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:39:49,221] {logging_mixin.py:104} INFO - [2021-08-19 17:39:49,221] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:39:49,234] {logging_mixin.py:104} INFO - [2021-08-19 17:39:49,233] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:39:49,234] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:39:49,256] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.041 seconds
[2021-08-19 17:40:19,373] {scheduler_job.py:181} INFO - Started process (PID=1473) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:40:19,377] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:40:19,378] {logging_mixin.py:104} INFO - [2021-08-19 17:40:19,378] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:40:19,385] {logging_mixin.py:104} INFO - [2021-08-19 17:40:19,384] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:40:19,385] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:40:19,406] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.035 seconds
[2021-08-19 17:40:49,864] {scheduler_job.py:181} INFO - Started process (PID=1527) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:40:49,865] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:40:49,866] {logging_mixin.py:104} INFO - [2021-08-19 17:40:49,866] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:40:49,876] {logging_mixin.py:104} INFO - [2021-08-19 17:40:49,875] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:40:49,876] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:40:49,896] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.034 seconds
[2021-08-19 17:41:19,984] {scheduler_job.py:181} INFO - Started process (PID=1589) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:41:19,985] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:41:19,986] {logging_mixin.py:104} INFO - [2021-08-19 17:41:19,986] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:41:20,004] {logging_mixin.py:104} INFO - [2021-08-19 17:41:20,002] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:41:20,005] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:41:20,031] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.051 seconds
[2021-08-19 17:41:50,710] {scheduler_job.py:181} INFO - Started process (PID=1653) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:41:50,712] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:41:50,712] {logging_mixin.py:104} INFO - [2021-08-19 17:41:50,712] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:41:50,724] {logging_mixin.py:104} INFO - [2021-08-19 17:41:50,722] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:41:50,724] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:41:50,746] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.039 seconds
[2021-08-19 17:42:21,074] {scheduler_job.py:181} INFO - Started process (PID=1705) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:42:21,075] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:42:21,076] {logging_mixin.py:104} INFO - [2021-08-19 17:42:21,076] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:42:21,090] {logging_mixin.py:104} INFO - [2021-08-19 17:42:21,088] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:42:21,090] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:42:21,114] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.046 seconds
[2021-08-19 17:42:51,163] {scheduler_job.py:181} INFO - Started process (PID=1769) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:42:51,164] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:42:51,165] {logging_mixin.py:104} INFO - [2021-08-19 17:42:51,165] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:42:51,173] {logging_mixin.py:104} INFO - [2021-08-19 17:42:51,172] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:42:51,173] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:42:51,200] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.041 seconds
[2021-08-19 17:43:21,398] {scheduler_job.py:181} INFO - Started process (PID=1830) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:43:21,399] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:43:21,400] {logging_mixin.py:104} INFO - [2021-08-19 17:43:21,400] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:43:21,409] {logging_mixin.py:104} INFO - [2021-08-19 17:43:21,408] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:43:21,409] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:43:21,432] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.037 seconds
[2021-08-19 17:43:51,832] {scheduler_job.py:181} INFO - Started process (PID=1886) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:43:51,833] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:43:51,833] {logging_mixin.py:104} INFO - [2021-08-19 17:43:51,833] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:43:51,844] {logging_mixin.py:104} INFO - [2021-08-19 17:43:51,844] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:43:51,845] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:43:51,866] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.037 seconds
[2021-08-19 17:44:22,087] {scheduler_job.py:181} INFO - Started process (PID=1950) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:44:22,088] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:44:22,088] {logging_mixin.py:104} INFO - [2021-08-19 17:44:22,088] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:44:22,098] {logging_mixin.py:104} INFO - [2021-08-19 17:44:22,097] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:44:22,099] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:44:22,121] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.037 seconds
[2021-08-19 17:44:52,337] {scheduler_job.py:181} INFO - Started process (PID=2002) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:44:52,338] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:44:52,338] {logging_mixin.py:104} INFO - [2021-08-19 17:44:52,338] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:44:52,345] {logging_mixin.py:104} INFO - [2021-08-19 17:44:52,345] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:44:52,346] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:44:52,367] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.033 seconds
[2021-08-19 17:45:01,837] {scheduler_job.py:181} INFO - Started process (PID=2024) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:45:01,838] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:45:01,839] {logging_mixin.py:104} INFO - [2021-08-19 17:45:01,839] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:45:01,846] {logging_mixin.py:104} INFO - [2021-08-19 17:45:01,845] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:45:01,847] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:45:01,868] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.034 seconds
[2021-08-19 17:45:31,976] {scheduler_job.py:181} INFO - Started process (PID=2087) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:45:31,977] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:45:31,978] {logging_mixin.py:104} INFO - [2021-08-19 17:45:31,978] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:45:31,985] {logging_mixin.py:104} INFO - [2021-08-19 17:45:31,984] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:45:31,986] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:45:32,006] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.033 seconds
[2021-08-19 17:46:02,106] {scheduler_job.py:181} INFO - Started process (PID=2137) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:46:02,107] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:46:02,107] {logging_mixin.py:104} INFO - [2021-08-19 17:46:02,107] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:46:02,119] {logging_mixin.py:104} INFO - [2021-08-19 17:46:02,118] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:46:02,120] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:46:02,143] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.040 seconds
[2021-08-19 17:46:32,888] {scheduler_job.py:181} INFO - Started process (PID=2201) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:46:32,889] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:46:32,889] {logging_mixin.py:104} INFO - [2021-08-19 17:46:32,889] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:46:32,899] {logging_mixin.py:104} INFO - [2021-08-19 17:46:32,897] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:46:32,900] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:46:32,924] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.040 seconds
[2021-08-19 17:47:03,676] {scheduler_job.py:181} INFO - Started process (PID=2265) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:47:03,677] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:47:03,677] {logging_mixin.py:104} INFO - [2021-08-19 17:47:03,677] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:47:03,685] {logging_mixin.py:104} INFO - [2021-08-19 17:47:03,684] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:47:03,685] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:47:03,707] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.034 seconds
[2021-08-19 17:47:34,336] {scheduler_job.py:181} INFO - Started process (PID=2318) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:47:34,337] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:47:34,338] {logging_mixin.py:104} INFO - [2021-08-19 17:47:34,338] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:47:34,353] {logging_mixin.py:104} INFO - [2021-08-19 17:47:34,351] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 12, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:47:34,353] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:47:34,379] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.045 seconds
[2021-08-19 17:48:05,136] {scheduler_job.py:181} INFO - Started process (PID=2382) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:48:05,137] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:48:05,137] {logging_mixin.py:104} INFO - [2021-08-19 17:48:05,137] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:48:05,146] {logging_mixin.py:104} INFO - /opt/airflow
[2021-08-19 17:48:05,147] {logging_mixin.py:104} INFO - [2021-08-19 17:48:05,146] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/web_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/web_scraping.py", line 9, in <module>
    from scripts.scroller import get_data
  File "/opt/airflow/dags/scripts/scroller.py", line 13, in <module>
    filehand = logging.FileHandler(log_file_path)
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1032, in __init__
    StreamHandler.__init__(self, self._open())
  File "/usr/local/lib/python3.6/logging/__init__.py", line 1061, in _open
    return open(self.baseFilename, self.mode, encoding=self.encoding)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/crawl_url/logging_test.log'
[2021-08-19 17:48:05,148] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:48:05,171] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.039 seconds
[2021-08-19 17:48:35,574] {scheduler_job.py:181} INFO - Started process (PID=2445) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:48:35,576] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:48:35,577] {logging_mixin.py:104} INFO - [2021-08-19 17:48:35,577] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:48:35,600] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:48:35,630] {logging_mixin.py:104} INFO - [2021-08-19 17:48:35,630] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 17:48:35,651] {logging_mixin.py:104} INFO - [2021-08-19 17:48:35,651] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T17:45:00+00:00
[2021-08-19 17:48:35,668] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.099 seconds
[2021-08-19 17:49:05,692] {scheduler_job.py:181} INFO - Started process (PID=2499) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:49:05,693] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:49:05,693] {logging_mixin.py:104} INFO - [2021-08-19 17:49:05,693] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:49:05,709] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:49:05,738] {logging_mixin.py:104} INFO - [2021-08-19 17:49:05,738] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 17:49:05,757] {logging_mixin.py:104} INFO - [2021-08-19 17:49:05,757] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T17:45:00+00:00
[2021-08-19 17:49:05,771] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.082 seconds
[2021-08-19 17:49:36,087] {scheduler_job.py:181} INFO - Started process (PID=2564) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:49:36,089] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:49:36,090] {logging_mixin.py:104} INFO - [2021-08-19 17:49:36,089] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:49:36,108] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:49:36,134] {logging_mixin.py:104} INFO - [2021-08-19 17:49:36,134] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 17:49:36,154] {logging_mixin.py:104} INFO - [2021-08-19 17:49:36,154] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T17:45:00+00:00
[2021-08-19 17:49:36,168] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.085 seconds
[2021-08-19 17:50:06,304] {scheduler_job.py:181} INFO - Started process (PID=2628) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:50:06,305] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:50:06,306] {logging_mixin.py:104} INFO - [2021-08-19 17:50:06,306] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:50:06,331] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:50:06,355] {logging_mixin.py:104} INFO - [2021-08-19 17:50:06,355] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 17:50:06,375] {logging_mixin.py:104} INFO - [2021-08-19 17:50:06,375] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T17:45:00+00:00
[2021-08-19 17:50:06,390] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.090 seconds
[2021-08-19 17:50:36,572] {scheduler_job.py:181} INFO - Started process (PID=2680) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:50:36,573] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:50:36,574] {logging_mixin.py:104} INFO - [2021-08-19 17:50:36,574] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:50:36,589] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:50:36,612] {logging_mixin.py:104} INFO - [2021-08-19 17:50:36,612] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 17:50:36,629] {logging_mixin.py:104} INFO - [2021-08-19 17:50:36,628] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T17:45:00+00:00
[2021-08-19 17:50:36,641] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.073 seconds
[2021-08-19 17:51:06,761] {scheduler_job.py:181} INFO - Started process (PID=2743) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:51:06,762] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:51:06,763] {logging_mixin.py:104} INFO - [2021-08-19 17:51:06,762] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:51:06,782] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:51:06,807] {logging_mixin.py:104} INFO - [2021-08-19 17:51:06,806] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 17:51:06,828] {logging_mixin.py:104} INFO - [2021-08-19 17:51:06,828] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T17:45:00+00:00
[2021-08-19 17:51:06,840] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.082 seconds
[2021-08-19 17:51:36,933] {scheduler_job.py:181} INFO - Started process (PID=2796) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:51:36,934] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:51:36,935] {logging_mixin.py:104} INFO - [2021-08-19 17:51:36,935] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:51:36,949] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:51:36,973] {logging_mixin.py:104} INFO - [2021-08-19 17:51:36,972] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 17:51:36,991] {logging_mixin.py:104} INFO - [2021-08-19 17:51:36,991] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T17:45:00+00:00
[2021-08-19 17:51:37,006] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.076 seconds
[2021-08-19 17:52:07,742] {scheduler_job.py:181} INFO - Started process (PID=2861) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:52:07,743] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:52:07,743] {logging_mixin.py:104} INFO - [2021-08-19 17:52:07,743] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:52:07,765] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:52:07,793] {logging_mixin.py:104} INFO - [2021-08-19 17:52:07,793] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 17:52:07,814] {logging_mixin.py:104} INFO - [2021-08-19 17:52:07,814] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T17:45:00+00:00
[2021-08-19 17:52:07,830] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.091 seconds
[2021-08-19 17:52:38,195] {scheduler_job.py:181} INFO - Started process (PID=2915) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:52:38,196] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:52:38,196] {logging_mixin.py:104} INFO - [2021-08-19 17:52:38,196] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:52:38,211] {scheduler_job.py:642} INFO - DAG(s) dict_keys(['web_scarp']) retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:52:38,235] {logging_mixin.py:104} INFO - [2021-08-19 17:52:38,235] {dag.py:1833} INFO - Sync 1 DAGs
[2021-08-19 17:52:38,254] {logging_mixin.py:104} INFO - [2021-08-19 17:52:38,254] {dag.py:2306} INFO - Setting next_dagrun for web_scarp to 2021-08-19T17:45:00+00:00
[2021-08-19 17:52:38,269] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.079 seconds
[2021-08-19 17:59:56,690] {scheduler_job.py:181} INFO - Started process (PID=45) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:59:56,698] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:59:56,701] {logging_mixin.py:104} INFO - [2021-08-19 17:59:56,700] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:59:56,701] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:59:56,703] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.024 seconds
[2021-08-19 17:59:56,758] {scheduler_job.py:181} INFO - Started process (PID=46) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 17:59:56,766] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 17:59:56,769] {logging_mixin.py:104} INFO - [2021-08-19 17:59:56,768] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:59:56,769] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 17:59:56,770] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.025 seconds
[2021-08-19 18:02:18,093] {scheduler_job.py:181} INFO - Started process (PID=45) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 18:02:18,101] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 18:02:18,104] {logging_mixin.py:104} INFO - [2021-08-19 18:02:18,103] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 18:02:18,105] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 18:02:18,106] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.048 seconds
[2021-08-19 18:04:58,926] {scheduler_job.py:181} INFO - Started process (PID=44) to work on /opt/airflow/dags/web_scraping.py
[2021-08-19 18:04:58,948] {scheduler_job.py:632} INFO - Processing file /opt/airflow/dags/web_scraping.py for tasks to queue
[2021-08-19 18:04:58,951] {logging_mixin.py:104} INFO - [2021-08-19 18:04:58,950] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/web_scraping.py
[2021-08-19 18:04:58,951] {scheduler_job.py:644} WARNING - No viable dags retrieved from /opt/airflow/dags/web_scraping.py
[2021-08-19 18:04:58,952] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/web_scraping.py took 0.038 seconds
